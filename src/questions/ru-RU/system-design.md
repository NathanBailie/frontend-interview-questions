<a href="./README.md">← Назад</a>

<div align="center">
  <img src="../../assets/icons/icons-for-titles/system-design.png">
  <h2>System Design</h2>
</div>
<br />

<details>
<summary><span>1. Какие есть <b>архитектуры ИС</b>?</span></summary>
<br />

1. **Файл-сервер** — простая архитектура, где сервер лишь хранит файлы, а обработка данных идет на ПК пользователя.

   > _Примеры:_ Локальные сети малых офисов с общими папками, старые версии систем «1С:Предприятие 7.7», простые базы данных на базе Microsoft Access.

2. **Клиент-сервер** — разделение на поставщиков (серверы) и заказчиков (клиенты) услуг.

   > _Примеры:_ Современные веб-сайты, банковские системы, онлайн-игры (например, World of Warcraft), корпоративные ERP-системы (SAP, Oracle).

3. **Peer to Peer (P2P)** — децентрализованная сеть, где каждый участник одновременно является и клиентом, и сервером.
   > _Примеры:_ Сеть BitTorrent для обмена файлами, блокчейн-сети (Bitcoin, Ethereum), мессенджеры с прямым шифрованием (некоторые функции Signal или Briar).

</details>

---

<details>
<summary><span>2. Основные <b>критерии систем</b>?</span></summary>
<br />

- **Доступность (Availability)** — доля времени, в течение которого система находится в рабочем состоянии и готова отвечать на запросы пользователей (часто измеряется в «девятках», например, 99.9%).
- **Эффективность** — способность системы выполнять задачи с минимальными затратами ресурсов (процессорного времени, памяти, трафика).
- **Надежность** — способность системы безотказно работать в заданных условиях в течение определенного времени.
- **Масштабируемость** — возможность системы справляться с растущей нагрузкой путем добавления ресурсов без изменения архитектуры.
- **Безопасность** — комплекс мер по защите данных от кражи, искажения или блокировки доступа.
- **Управляемость** — простота мониторинга, настройки и обновления системы в процессе эксплуатации.
- **Производительность (Performance)** — количественная характеристика того, как быстро система выполняет операции и какой объем данных может обработать.

</details>

---

<details>
<summary><span>3. Каким бывает <b>масштабирвание</b>?</span></summary>
<br />

- **Вертикальное масштабирование (Scale-up)** — увеличение производительности системы за счет наращивания мощности одного узла (увеличение объема RAM, количества ядер процессора или скорости дисков).

  > _Пример:_ Покупка более мощного сервера для базы данных.

- **Горизонтальное масштабирование (Scale-out)** — увеличение производительности за счет добавления новых узлов (серверов) в систему, которые работают параллельно.

  > _Пример:_ Добавление десяти обычных серверов в кластер для распределения веб-трафика.

Вертикальное масштабирование проще в реализации, но имеет физический «потолок», в то время как горизонтальное - почти безгранично, но требует более сложной архитектуры ПО.

</details>

---

<details>
<summary><span>4. Что такое <b>SLA / SLO / SLI?</b></span></summary>
<br />

- **SLI (Service Level Indicator)** — это конкретный количественный показатель (метрика), который мы измеряем здесь и сейчас. Это «градусник» системы

  > _Пример:_ Время ответа сервера (latency) или процент успешных запросов (error rate).

- **SLO (Service Level Objective)** — это целевое значение или диапазон значений для выбранного SLI, который мы хотим поддерживать. Это внутренняя цель команды инженеров.

  > _Пример:_ «99,9% запросов должны обрабатываться быстрее чем за 200 мс».

- **SLA (Service Level Agreement)** — это внешнее обязательство (договор) перед клиентом, в котором прописано, что будет, если SLO не будет достигнут.Это юридический документ с финансовыми последствиями (штрафы, возвраты).
  > _Пример:_ «Если доступность сервиса упадет ниже 99%, мы вернем клиентам 10% стоимости подписки».

**Важный нюанс:** Инженеры обычно стараются сделать **SLO чуть строже, чем SLA**. Это создает «запас прочности» (Error Budget), чтобы успеть починить систему до того, как придется платить штрафы клиентам.

</details>

---

<details>
<summary><span>5. Что такое <b>Stateless / Stateful</b>?</span></summary>
<br />

- **Stateless (Без сохранения состояния)** — архитектура, при которой сервер не хранит информацию о предыдущих запросах клиента. Каждый запрос должен содержать абсолютно все данные, необходимые для его обработки.

  > _Пример:_ Поиск в Google. Каждый ваш поисковый запрос автономен. Если вы закроете вкладку и откроете снова, сервер не будет "помнить", что вы искали минуту назад, пока вы не отправите новый запрос.

- **Stateful (С сохранением состояния)** — архитектура, в которой сервер «помнит» контекст взаимодействия с клиентом. Состояние (сессия) хранится на стороне сервера и влияет на обработку последующих запросов.
  > _Пример:_ Старый интернет-магазин с корзиной на сессиях. Вы добавляете товар в корзину на одном сервере, и этот сервер хранит список товаров в своей памяти. Если следующий запрос попадет на другой сервер (без синхронизации), корзина окажется пустой.

---

**Краткое сравнение:**

| Критерий               | Stateless                                              | Stateful                                                |
| ---------------------- | ------------------------------------------------------ | ------------------------------------------------------- |
| **Масштабируемость**   | Высокая (любой сервер обработает любой запрос)         | Сложная (нужна синхронизация данных между серверами)    |
| **Отказоустойчивость** | Высокая (падение сервера не теряет данные клиента)     | Ниже (при падении сервера теряется сессия пользователя) |
| **Передача данных**    | Запросы тяжелее (нужно каждый раз слать токены/данные) | Запросы легче (сервер уже знает, кто вы и что делали)   |

</details>

---

<details>
<summary><span>6. Что такое <b>Latency, Response Time, Throughput?</b></span></summary>
<br />

- **Latency (Задержка)** — это время, которое требуется пакету данных или запросу, чтобы пройти путь от отправителя до получателя. Это чистая «задержка в пути».

  > _Пример:_ Время, за которое электрический сигнал доходит от вашего ПК до игрового сервера.

- **Response Time (Время отклика)** — это полное время, которое пользователь ждет ответа после отправки запроса. Оно включает в себя _Latency_ + время, затраченное сервером на обработку задачи.

  > _Пример:_ Вы нажали «Купить», запрос дошел до сервера (задержка), сервер проверил баланс и списал деньги (обработка), и ответ вернулся вам. Всё это вместе — время отклика.

- **Throughput (Пропускная способность)** — это количество запросов или объем данных, которые система может обработать за определенный промежуток времени.
  > _Пример:_ Веб-сервер, обрабатывающий 5000 запросов в секунду (RPS), или канал связи со скоростью 100 Мбит/с.

---

**Простая аналогия:**
Представьте дорогу.

- **Latency** — это то, как быстро одна машина проезжает от города А до города Б (скорость).
- **Throughput** — это то, сколько машин может проехать по этой дороге за час (количество полос).

Эти метрики тесно связаны: если **Throughput** достигает своего предела, запросы начинают вставать в очередь, что мгновенно увеличивает **Response Time**.

</details>

---

<details>
<summary><span>7. Типы нагрузки: <b>Data-intensive vs Compute-intensive?</b></span></summary>
<br />

- **Data-intensive (Интенсивные по данным)** — системы, где основной сложностью является объем данных, их сложность или скорость их изменения, а не вычисления.

  > _Пример:_ Социальные сети (Facebook, Instagram) или базы данных, где нужно быстро сохранять и искать миллиарды постов.

- **Compute-intensive (Интенсивные по вычислениям)** — системы, где на первый план выходит нагрузка на процессор (CPU). Данных может быть немного, но алгоритмы их обработки очень сложные.
  > _Пример:_ Сервисы видеомонтажа, рендеринг 3D-графики, майнинг криптовалют или обучение нейросетей.

</details>

---

<details>
<summary><span>8. Что такое <b>Read / Write Ratio?</b></span></summary>
<br />

- **Read / Write Ratio (Соотношение чтения и записи)** — показатель, который определяет, какая операция в системе преобладает. От этого зависит выбор архитектуры базы данных и стратегии кэширования.
- **Read-heavy (Тяжелое чтение)** — пользователи читают данные гораздо чаще, чем создают новые.

  > _Пример:_ Новостной портал или Википедия (одну статью пишут один раз, а читают миллионы). Здесь критически важен **кэш**.

- **Write-heavy (Тяжелая запись)** — система получает огромный поток входящих данных, которые нужно успевать записывать.

  > _Пример:_ Системы сбора логов, датчики интернета вещей (IoT) или биржевые котировки. Здесь важна **высокая пропускная способность БД на запись**.

  **Почему это важно для архитектора?**
  Если ты понимаешь, что система **Read-heavy**, ты добавишь **Read-реплики** для базы данных. А если она **Compute-intensive**, ты будешь думать о вертикальном масштабировании CPU или использовании GPU.

</details>

---

<details>
<summary><span>9. Какой бывает <b>архитектура бэкенда?</b></span></summary>
<br />

- **Монолит (Monolith)** — архитектура, в которой все компоненты приложения (логика, работа с БД, интерфейс) собраны в один единый исполняемый файл или проект.

  > _Пример:_ Небольшой интернет-магазин, написанный на Django или Ruby on Rails, где весь код живет в одном репозитории и разворачивается целиком.

- **Микросервисы (Microservices)** — подход, при котором приложение разбивается на набор маленьких, независимых сервисов, каждый из которых отвечает за свою бизнес-функцию и общается с другими по сети (API).

  > _Пример:_ Netflix или Amazon. Один сервис отвечает за авторизацию, другой за рекомендации, третий за оплату. Если "упадет" сервис рекомендаций, пользователи всё равно смогут оплатить подписку.

  **Важный совет:** Обычно рекомендуют начинать с **монолита**, чтобы быстро проверить идею (MVP), и переходить на **микросервисы** только тогда, когда команда и нагрузка вырастут настолько, что монолит станет "тесным".

</details>

---

<details>
<summary><span>10. Плюсы и минусы монолитной и микросервисной архитектуры</span></summary>
<br />

### **1. Монолитная архитектура**

Подходит для небольших команд, стартапов и систем с невысокой сложностью бизнес-логики.

| Характеристика         | Плюсы (+)                                                                           | Минусы (−)                                                                                               |
| ---------------------- | ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| **Разработка**         | **Простота:** единый код, общие модели данных и легкая навигация по проекту.        | **Запутанность:** со временем код превращается в «большой ком грязи», который трудно менять.             |
| **Тестирование**       | **Легкость:** можно запустить всё приложение целиком и провести сквозные тесты.     | **Риск:** небольшое изменение в одном модуле может неожиданно сломать другую часть системы.              |
| **Производительность** | **Скорость:** вызовы функций внутри памяти происходят мгновенно, без задержек.      | **Барьер роста:** нельзя масштабировать только одну нагруженную функцию — нужно копировать весь монолит. |
| **Деплой**             | **Удобство:** нужно доставить и запустить всего один артефакт (файл или контейнер). | **Долгое ожидание:** сборка и запуск огромного проекта могут занимать десятки минут.                     |

---

### **2. Микросервисная архитектура**

Оправдана в крупных проектах с сотнями разработчиков и необходимостью гибкого масштабирования.

| Характеристика         | Плюсы (+)                                                                                      | Минусы (−)                                                                                              |
| ---------------------- | ---------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| **Масштабирование**    | **Точечность:** можно добавить мощности только сервису оплаты или поиска, не трогая остальное. | **Сложность:** требуется сложная настройка инфраструктуры (Kubernetes, Service Mesh).                   |
| **Отказоустойчивость** | **Изоляция:** если «упал» сервис рекомендаций, каталог и корзина продолжат работать.           | **Сетевые сбои:** вызовы по сети могут обрываться, зависать или приходить с задержками.                 |
| **Стек технологий**    | **Гибкость:** можно использовать разные языки (Go для скорости, Python для ML) под задачи.     | **Зоопарк технологий:** трудно поддерживать единые стандарты качества и безопасности в разных командах. |
| **Командная работа**   | **Автономия:** команды работают независимо, не мешая друг другу и не дожидаясь чужих правок.   | **Согласованность:** трудно поддерживать актуальность данных в разных БД (проблема целостности).        |

> _Пример выбора:_ Если вы делаете MVP приложения для доставки еды — выбирайте **монолит**. Если вы строите гиганта уровня Uber или Amazon — вам не обойтись без **микросервисов**.

</details>

---

<details>
<summary><span>11. Где может происходить <b> балансировка нагрузки?</b></span></summary>
<br />

- **Клиентская балансировка** — клиент сам знает адреса серверов и выбирает, к какому обратиться.

  > _Пример:_ Клиентское приложение получает список IP-адресов от Service Discovery и само решает, куда слать запрос.

- **Серверная балансировка** — между клиентом и серверами стоит посредник (Load Balancer), который принимает все запросы и распределяет их.

  > _Пример:_ Nginx или HAProxy, стоящие перед кластером серверов.

- **DNS / GeoDNS балансировка** — распределение на уровне разрешения доменного имени. GeoDNS направляет пользователя на ближайший к нему дата-центр.
  > _Пример:_ Запрос из Европы направляется на сервер во Франкфурте, а из Азии — в Сингапур.

</details>

---

<details>
<summary><span>12. Какие есть <b>алгоритмы распределения нагрузки?</b></span></summary>
<br />

- **Random (Рандом)** — выбор случайного сервера. Просто, но может привести к неравномерной нагрузке.
- **Round Robin (RR)** — запросы передаются серверам по очереди (1-й, 2-й, 3-й и снова 1-й).
- **Weighted Round Robin (WRR)** — то же самое, но с учетом мощности (веса) сервера.

  > _Пример:_ Мощный сервер получает 3 запроса, а слабый — только 1.

- **Least Connections / Response Time / Bandwidth** — запрос уходит серверу с наименьшим количеством активных соединений, самым быстрым ответом или свободной полосой пропускания.
- **Power of Two Choices** — выбираются два случайных сервера, и из них запрос уходит тому, кто меньше нагружен. Это эффективнее, чем просто Random.
- **Sticky Sessions (Сессии)** — закрепление конкретного пользователя за конкретным сервером (обычно через Cookie).
  > _Пример:_ Нужно в **Stateful** архитектурах, чтобы корзина пользователя не «потерялась» при переходе на другой сервер.
  </details>

---

<details>
<summary><span>13. Какие есть <b>уровни балансировки (OSI) нагрузки?</b></span></summary>
<br />

- **L4 (Транспортный уровень)** — балансировка на основе IP и портов. Очень быстрая, так как не читает содержимое пакета.
- **L7 (Прикладной уровень)** — балансировка на основе содержимого запроса (URL, заголовки, Cookies). Позволяет делать умную маршрутизацию.
  > _Пример:_ Запросы `/api/video` отправлять на одни серверы, а `/api/images` — на другие.

</details>

---

<details>
<summary><span>14. Какие есть <b>виды проксирования?</b></span></summary>
<br />

- **Forward Proxy (Прямой прокси)** — сервер, который стоит между группой клиентов и интернетом. Он скрывает личность клиента от сервера и контролирует исходящий трафик.

  > _Пример:_ Корпоративный прокси в офисе, который запрещает сотрудникам заходить в соцсети или скрывает их реальные IP-адреса от внешних сайтов.

- **Reverse Proxy (Обратный прокси)** — сервер, который стоит перед одним или группой веб-серверов. Он принимает запросы из интернета и распределяет их между внутренними серверами. Клиент даже не знает, что общается не напрямую с целевым сервером.
  > _Пример:_ **Nginx** или **HAProxy**, которые стоят «на входе» в систему. Они занимаются балансировкой нагрузки, шифрованием (SSL-терминация) и кэшированием статики.

---

**Ключевое отличие:**

- **Forward Proxy** защищает и анонимизирует **клиента**.
- **Reverse Proxy** защищает и оптимизирует работу **сервера**.

**Reverse Proxy** — это «сердце» любой современной архитектуры. Он не только распределяет нагрузку, но и может выполнять роль **API Gateway**.

</details>

---

<details>
<summary><span>15. Для чего нужно <b>кэширование?</b></span></summary>
<br />

**Кэширование** — это один из самых эффективных способов ускорить систему и снизить нагрузку на базу данных за счет временного хранения часто запрашиваемых данных в быстрой памяти (RAM).

**Зачем оно нужно:**

1. **Ускорение отклика:** Данные из памяти отдаются в десятки раз быстрее, чем из дисковой БД.
2. **Снижение нагрузки на БД:** Повторные запросы не «дергают» тяжелую базу.
3. **Экономия ресурсов:** Уменьшается потребление CPU и сетевого трафика на повторные вычисления.

---

**Ключевые термины:**

- **Cache Hit (Попадание в кэш)** — успешная ситуация, когда запрошенные данные были найдены в кэше и сразу отданы клиенту.
- **Cache Miss (Промах)** — ситуация, когда данных в кэше не оказалось, и системе пришлось идти за ними в медленную базу данных.
- **Hit Ratio** — метрика эффективности кэша. Отношение количества «попаданий» к общему числу запросов.

  > _Пример:_ Если из 100 запросов 90 были отданы из кэша, Hit Ratio = 90%. Чем он выше, тем лучше настроен кэш.

- **Инвалидация кэша** — процесс удаления или обновления устаревших данных в кэше, чтобы пользователь не видел неактуальную информацию.

  > _Пример:_ Когда цена товара в БД изменилась, нужно «инвалидировать» старую цену в кэше, иначе клиент увидит неверную стоимость.

- **Прогрев кэша (Warm-up)** — предварительное заполнение кэша данными (обычно сразу после запуска системы), чтобы первые пользователи не столкнулись с медленной работой из-за _Cache Miss_.

  > _Пример:_ Скрипт, который после деплоя «прокликивает» самые популярные страницы, чтобы они попали в кэш.

- **Горячий ключ (Hot Key)** — это ключ (данные), к которому обращается аномально большое количество пользователей одновременно.
  > _Пример:_ Пост знаменитости с миллионами подписчиков или страница товара в «Черную пятницу». Горячие ключи могут перегрузить даже сам сервер кэширования.

</details>

---

<details>
<summary><span>16. Какие данные стоит кэшировать?</span></summary>
<br />

Выбор данных для кэширования обычно основывается на принципе **«часто запрашиваются, редко меняются»**.

- **Статические файлы** — изображения, JS/CSS скрипты, шрифты. Это самый простой и эффективный вид кэширования.

  > _Пример:_ Логотип компании на главной странице, который не меняется годами.

- **Результаты тяжелых запросов к БД** — данные, на получение которых уходит много времени и ресурсов сервера.

  > _Пример:_ Список топ-100 популярных товаров, который собирается из нескольких огромных таблиц с агрегацией.

- **Данные профилей пользователей (сессии)** — информация о том, авторизован ли пользователь и какие у него права.

  > _Пример:_ Имя пользователя и его аватар, которые отображаются на каждой странице сайта.

- **Ответы от внешних API** — если ваша система запрашивает данные у сторонних сервисов, которые работают медленно или берут деньги за каждый запрос.

  > _Пример:_ Курс валют от ЦБ, который обновляется раз в сутки, или прогноз погоды.

- **Результаты сложных вычислений** — данные, требующие больших затрат CPU.
  > _Пример:_ Сформированный PDF-отчет за прошлый месяц или результат работы алгоритма рекомендаций.

---

**Что НЕ стоит кэшировать:**

1. **Часто меняющиеся данные:** Если данные обновляются раз в секунду, кэш будет постоянно инвалидироваться и не принесет пользы.
2. **Персональные/секретные данные других пользователей:** Ошибка в логике кэширования может привести к тому, что один пользователь увидит данные карты другого.
3. **Данные с низкой вероятностью повторного использования:** Кэширование редких запросов («Хвост» или Long Tail) только тратит дорогую память RAM.

Важно помнить про **Read / Write Ratio**: чем больше система ориентирована на чтение (Read-heavy), тем больше пользы принесет кэширование.

</details>

---

<details>
<summary><span>17. Нужно ли <b>кэширование ошибок?</b></span></summary>
<br />

Кэширование ошибок (также известное как **Negative Caching**) — это продвинутая техника, которая помогает защитить систему от «эффекта домино» при сбоях или атаках.

**Да, это необходимо**, но с определенными условиями. Кэширование ответов об отсутствии данных или временных сбоях предотвращает перегрузку системы.

**Зачем это нужно:**

- **Защита от «мусорных» запросов:** Если кто-то (или бот) запрашивает несуществующие данные миллион раз, система не будет каждый раз обращаться к БД, а сразу отдаст ошибку из кэша.
- **Снижение нагрузки при сбоях:** Если база данных временно недоступна, кэширование ошибки позволит серверу не тратить время на ожидание тайм-аута при каждом новом запросе.

---

**Что именно кэшировать:**

- **Ошибка 404 (Not Found)** — если ресурса нет, лучше запомнить это на короткое время.

  > _Пример:_ Запрос профиля пользователя, который был удален.

- **Ошибки авторизации (401/403)** — помогает защититься от Brute-force атак (подбора паролей).
- **Пустые результаты поиска** — если по запросу «розовый слон в скафандре» ничего не найдено, нет смысла искать это снова в следующие 5 минут.

---

**Главные правила (Best Practices):**

1. **Короткий TTL (Time To Live):** Ошибки должны жить в кэше гораздо меньше, чем успешные ответы.

   > _Пример:_ Успешный ответ кэшируем на 1 час, а ошибку 404 — на 1-2 минуты.

2. **Разделение типов ошибок:** Нельзя кэшировать ошибку 500 (Internal Server Error) надолго, так как она может быть исправлена через секунду.
3. **Безопасность:** Убедитесь, что закэшированная ошибка не содержит чувствительной информации о структуре вашей системы или БД.

Кэширование ошибок — это отличный способ повысить **Доступность** системы под нагрузкой.

</details>

---

<details>
<summary><span>18. Всегда ли кэширование полезно?</span></summary>
<br />

Нет, кэширование — это не всегда благо. В некоторых сценариях оно может не только быть бесполезным, но и навредить производительности или корректности данных.

Кэширование становится вредным или неэффективным в следующих случаях:

- **Низкий Hit Ratio (Редкие запросы)** — если данные запрашиваются повторно крайне редко, кэш просто занимает дорогую оперативную память, не принося пользы.

  > _Пример:_ База данных пользователей огромная, а люди заходят в профиль раз в год. Кэшировать все профили — пустая трата ресурсов.

- **Write-heavy нагрузка (Частые обновления)** — если данные меняются чаще, чем читаются, система будет тратить больше ресурсов на постоянную инвалидацию и обновление кэша, чем на само чтение.

  > _Пример:_ Котировки акций в реальном времени. Кэш станет неактуальным через миллисекунду после записи.

- **Критическая важность свежести данных** — в финансовых или медицинских системах даже задержка в пару секунд может быть недопустима.

  > _Пример:_ Баланс банковского счета. Пользователь не должен видеть старую сумму после того, как он только что снял деньги.

- **Ограниченность ресурсов (RAM)** — кэш живет в оперативной памяти, которая намного дороже дискового пространства. Если кэшировать всё подряд, системе не хватит памяти для выполнения основных процессов.
- **Усложнение логики (Проблема консистентности)** — поддержка кэша в актуальном состоянии требует сложного кода. Ошибки в инвалидации кэша — одна из самых частых причин багов, которые сложно воспроизвести.
  > _Пример:_ Пользователь сменил пароль, но кэш сессии на одном из серверов не обновился, и старый пароль всё еще работает.

---

**Когда кэш превращается в проблему:**

1. **Cache Stampede (Гонка за кэшем):** Когда у популярного ключа истекает срок жизни, и тысячи запросов одновременно «ломятся» в базу данных, чтобы обновить его, создавая лавинообразную нагрузку.
2. **Pollution (Загрязнение кэша):** Когда «одноразовые» данные вытесняют из памяти действительно полезные и часто используемые данные.

Именно поэтому перед внедрением кэша всегда стоит оценить **Read/Write Ratio** и выбрать правильную **стратегию вытеснения данных** (например, **LRU** — Least Recently Used).

</details>

---

<details>
<summary><span>19. Как <b>рассчитать эффективность кэша</b>?</span></summary>
<br />

Основной метрикой является **Среднее время доступа (Average Access Time)**.

$$T_{avg} = (HitRate \times T_{cache}) + (MissRate \times T_{db})$$
Где:

- **$Hit Rate$** — доля запросов, найденных в кэше (от 0 до 1).
- **$Miss Rate$** — доля запросов, которых не оказалось в кэше (1 - HitRate).
- **$T\_{cache}$** — время получения данных из кэша.
- **$T\_{db}$** — время получения данных из основного хранилища (БД).

---

### **Когда кэш становится вредным?**

Существует «правило большого пальца»: если **Cache Miss Rate > 0.8** (то есть вы не находите данные в кэше более чем в 80% случаев), кэш считается вредным.

**Почему это плохо:**

1. **Double Latency:** При промахе вы тратите время $T_{cache} + T_{db}$. Если промахов 80%, то для большинства запросов система работает медленнее, чем вообще без кэша.
2. **Бесполезный расход ресурсов:** Вы тратите дорогую оперативную память (RAM) и CPU на поддержку структуры кэша, которая не выполняет свою задачу.
3. **Засорение:** При таком высоком Miss Rate данные в кэше постоянно обновляются, создавая лишнюю нагрузку на запись в сам кэш.

> _Пример:_ > Допустим, время в кэше 1 мс, в БД 100 мс.
> Если **Miss Rate = 0.9** (90%), то $T\_{avg}$ = (0.1 $\times$ 1) + (0.9 $\times$ 101) $\approx$ 91 мс.
> Накладные расходы на проверку кэша в 90% случаев делают систему менее эффективной.

---

### **Как повысить эффективность (Hit Ratio)?**

- **Увеличить TTL:** Хранить данные дольше (если бизнес-логика позволяет).
- **Увеличить объем памяти:** Чтобы популярные данные не вытеснялись новыми.
- **Прогрев кэша:** Заполнять его данными до прихода реальных пользователей.

</details>

---

<details>
<summary><span>20. Какие есть <b>виды кэширования?</b>, плюсы и минусы?</span></summary>
<br />

### **1. Внутреннее кэширование (In-memory cache)**

Данные хранятся непосредственно в оперативной памяти самого приложения (например, в HashMap или специальных библиотеках вроде Caffeine/Guava).

| Плюсы (+)                                                                                                            | Минусы (−)                                                                                                                      |
| -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| **Экстремальная скорость:** данные читаются из памяти процесса, это самый быстрый способ.                            | **Проблемы масштабирования:** при горизонтальном масштабировании у каждого экземпляра приложения будет свой «кусочек» кэша.     |
| **Нет сетевых задержек:** не нужно обращаться к другому серверу.                                                     | **Трудности синхронизации:** если на Сервере А данные в кэше обновились, Сервер Б об этом не узнает (проблема консистентности). |
| **Нет расходов на (un)marshalling:** данные хранятся как готовые объекты языка, их не нужно превращать в JSON/байты. | **Прогрев после падения:** если приложение упадет, кэш полностью очистится и его придется наполнять с нуля.                     |

> _Пример:_ Хранение конфигурационных файлов или справочников стран, которые редко меняются.

---

### **2. Внешнее кэширование (Distributed cache)**

Кэш вынесен в отдельную систему (базу данных в памяти), к которой обращаются все экземпляры приложения.

> _Пример:_ Redis, Memcached.

| Плюсы (+)                                                                                  | Минусы (−)                                                                                                                            |
| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| **Общее состояние:** все серверы видят одни и те же актуальные данные.                     | **Скорость работы:** ниже, чем у внутреннего, так как добавляются сетевые задержки (Network Latency).                                 |
| **Масштабируемость:** можно хранить терабайты данных, просто добавляя узлы в кластер кэша. | **Маршалинг данных:** данные нужно сериализовать (например, в JSON или Protobuf), чтобы отправить по сети, и десериализовать обратно. |
| **Живучесть:** если приложение упадет и перезапустится, данные в кэше сохранятся.          | **Точка отказа:** если упадет сам Redis, «ослепнут» сразу все серверы приложения.                                                     |

> _Пример:_ Хранение сессий пользователей или корзин покупок в интернет-магазине.

---

**Итог:**

- Если данных мало и они статичны — используй **внутренний** кэш.
- Если система распределенная и данных много — выбирай **внешний**.

</details>

---

<details>
<summary><span>21. Какие есть <b>способы взаимодействия с кэшем</b>?</span></summary>
<br />

### **Стратегии чтения (Read)**

- **Cache Aside (Кэширование на стороне)** — приложение сначала идет в кэш; если данных нет (miss), читает из БД и само сохраняет их в кэш.

  > _Пример:_ Самый популярный подход. Приложение управляет всем процессом, а БД и кэш не знают друг о друге.

- **Read Through** — приложение всегда запрашивает данные только у кэша, а кэш сам идет в БД при промахе, обновляется и возвращает ответ.
  > _Пример:_ Позволяет упростить код приложения, переложив логику чтения на инфраструктуру кэша.

### **Стратегии записи (Write)**

- **Write Through** — данные записываются одновременно и в кэш, и в БД; запись считается успешной только после подтверждения от обоих.

  > _Пример:_ Гарантирует высокую актуальность данных в кэше, но замедляет запись из-за двойной операции.

- **Write Back (или Write Behind)** — приложение пишет данные только в кэш, а в БД они сохраняются асинхронно через некоторое время.

  > _Пример:_ Очень быстрая запись, подходит для систем сбора логов или счетчиков, где потеря нескольких секунд данных не критична.

- **Write Around** — данные пишутся напрямую в БД, минуя кэш. Кэш обновляется только при последующем чтении (через Cache Aside).
  > _Пример:_ Помогает не засорять кэш данными, которые записываются часто, но читаются редко.

### **Дополнительные техники**

- **Refresh-ahead (Cache Ahead)** — кэш автоматически обновляет данные до того, как истечет их срок жизни (TTL), если они часто запрашиваются.
  > _Пример:_ Система видит, что срок жизни популярной новости истекает через 10 секунд, и заранее делает запрос к БД, чтобы пользователь не столкнулся с ожиданием (latency).

Каждая из этих стратегий — это выбор между **скоростью** и **риском потери данных** или их рассогласования.

</details>

---

<details>
<summary><span>22. Какие есть <b>алгоритмы вытеснения данных?</b></span></summary>
<br />
Когда кэш переполняется, системе нужно решить, какие данные удалить, чтобы освободить место для новых. Эти правила называются **алгоритмами вытеснения (Eviction Policies)**.

### **Базовые алгоритмы**

- **Random (Рандом)** — удаляет случайный объект. Прост в реализации, но не учитывает полезность данных.
- **FIFO (First In, First Out)** — удаляет данные, которые были добавлены первыми (как в очереди), независимо от того, как часто их читали.
- **LIFO (Last In, First Out)** — удаляет данные, которые были добавлены последними. Используется редко.

### **Алгоритмы на основе обращения**

- **LRU (Least Recently Used)** — удаляет данные, которые **дольше всего не запрашивались**. Самый популярный алгоритм (баланс простоты и эффективности).
- **MRU (Most Recently Used)** — удаляет данные, которые запрашивались **последними**. Полезен, когда старые данные с большей вероятностью понадобятся снова.
- **LFU (Least Frequently Used)** — удаляет данные, которые запрашивались **реже всего** (считает количество обращений).
  > _Минус:_ старые популярные объекты могут «застрять» в кэше навсегда.

### **Продвинутые и комбинированные алгоритмы**

- **LRU-k** — учитывает время k-го последнего обращения. Позволяет лучше отличать популярные данные от случайных «разовых» запросов.
- **SLRU (Segmented LRU)** — кэш делится на две зоны: «пробная» (для новых данных) и «защищенная» (для часто запрашиваемых).
- **2Q (Two Queues)** — использует две очереди (FIFO и LRU), чтобы эффективно отсеивать данные, которые запрашиваются только один раз (защита от «сканирования» кэша).
- **TLRU (Time-aware LRU)** — учитывает не только время последнего обращения, но и срок жизни данных (TTL).

### **Аппроксимации и спец. алгоритмы**

- **Second Chance (Второй шанс)** — модификация FIFO. Если у элемента стоит «флаг обращения», ему дается второй шанс, и он перемещается в конец очереди вместо удаления.
- **Clock (Часы)** — более эффективная реализация Second Chance, где элементы стоят по кругу, а «стрелка» ищет кандидата на удаление.
- **Алгоритм Белади (OPT)** — теоретический идеал. Удаляет данные, которые не понадобятся **дольше всего в будущем**.
  > _Нюанс:_ Невозможен на практике, так как мы не знаем будущего. Используется как эталон для сравнения других алгоритмов.

В современных системах (например, в **Redis**) чаще всего используется **LRU** или его аппроксимации, так как они дают лучший результат при минимальных затратах ресурсов.

</details>

---

<details>
<summary><span>23. Какие есть <b>виды API?</b></span></summary>
<br />

### **1. REST (Representational State Transfer)**

Самый популярный стиль для веб-сервисов. Строится вокруг **ресурсов** (сущностей), доступ к которым осуществляется через стандартные HTTP-методы (**CRUD**).

- **Методы:** `GET` (чтение), `POST` (создание), `PUT/PATCH` (обновление), `DELETE` (удаление).
- **Плюсы:** Простота, кэширование, независимость клиента и сервера. Обычно использует JSON.

### **2. SOAP (Simple Object Access Protocol)**

Строгий протокол на базе XML. Часто встречается в банковских системах и старом корпоративном ПО.

- **Особенности:** Имеет жесткий стандарт (WSDL-файл), встроенную обработку ошибок и поддержку безопасности (WS-Security).
- **Плюсы:** Высокая надежность и строгость данных. **Минусы:** Избыточность (тяжелый XML) и сложность.

### **3. RPC (Remote Procedure Call)**

Концепция «вызова удаленной процедуры». Клиент вызывает функцию на сервере так, будто она находится в его собственном коде.

- **gRPC (Google RPC)** — современная реализация от Google. Использует **HTTP/2** и формат **Protocol Buffers** (бинарный код).
- **Плюсы:** Экстремально высокая скорость, двусторонняя потоковая передача данных, строгая типизация.
- **Минус:** Не читается человеком (нужна десериализация), сложно тестировать через браузер.

### **4. GraphQL**

Язык запросов для API, созданный Facebook. Позволяет клиенту самому определять, какие именно поля ему нужны.

- **Особенности:** У клиента есть одна точка входа (`/graphql`), куда он отправляет запрос с описанием структуры данных.
- **Плюсы:** Решает проблему **Overfetching** (лишние данные) и **Underfetching** (недостаток данных, требующий новых запросов).
- **Минус:** Сложность реализации на сервере и трудности с кэшированием.

---

**Краткое сравнение:**

- Нужен стандарт для фронтенда? — **REST**.
- Нужна скорость между микросервисами? — **gRPC**.
- Сложные данные и мобильные приложения? — **GraphQL**.
- Банковский сектор 15-летней давности? — **SOAP**.

</details>

---

<details>
<summary><span>24. Что такое <b>Underfetching</b> и <b>Overfetching</b> и как они связаны с GraphQL?</span></summary>
<br />

Эти термины описывают неэффективность передачи данных между клиентом и сервером.

### **1. Overfetching (Избыточная выборка)**

Это ситуация, когда клиент получает от сервера **больше данных, чем ему нужно** для отрисовки конкретного экрана.

- **Проблема:** Тратится лишний мобильный трафик, расходуется заряд батареи на парсинг тяжелых JSON-ответов, нагружается сеть.
- **Пример в REST:** Чтобы показать только _имена_ друзей в списке, вы вызываете `/api/friends`. Но сервер возвращает полный объект каждого друга: дату рождения, адрес, историю заказов и биографию. 90% этих данных вам сейчас не нужны.

### **2. Underfetching (Недостаточная выборка)**

Это ситуация, когда одного запроса к API **недостаточно**, чтобы получить все необходимые данные для экрана.

- **Проблема:** Клиенту приходится делать несколько последовательных (цепочечных) запросов, что увеличивает время ожидания (**Latency**) из-за постоянных сетевых «походов».
- **Пример в REST:** Вам нужно показать профиль пользователя и его последние 3 поста. Сначала вы делаете запрос `/user/1`, получаете ID постов, а затем делаете второй запрос `/user/1/posts`. Пока не завершится первый, вы не можете начать второй.

---

### **Внутреннее устройство (Как это решает GraphQL)**

В отличие от REST, где каждый URL — это фиксированный набор данных, **GraphQL** работает иначе:

1. **Единая точка входа (Endpoint):** Обычно это один URL (например, `/graphql`).
2. **Схема (Schema):** На сервере описываются все возможные типы данных и связи между ними (сильная типизация).
3. **Запрос (Query):** Клиент сам пишет структуру запроса, перечисляя только нужные поля.

   > _Решение Overfetching:_ Если вам нужно только `name`, вы пишете `name` в запросе, и сервер пришлет только его.

   > _Решение Underfetching:_ Вы можете в одном запросе попросить и данные профиля, и вложенный список постов. Сервер сам соберет их и отдаст одним ответом.

</details>

---

<details>
<summary><span>25. Что такое <b>Observability</b> и из чего она состоит?</span></summary>
<br />

**Observability** — это способность понимать внутреннее состояние системы, анализируя данные, которые она выдает наружу. Она состоит из «трех столпов» и дополнительных методов:

- **Monitoring (Мониторинг) & Metrics** — сбор числовых данных о работе системы в реальном времени. Помогает ответить на вопрос: «Система здорова?».
- **Logging (Логирование)** — запись текстовых событий. Помогает ответить на вопрос: «Что именно произошло?».
- **Tracing (Трейсинг)** — отслеживание пути одного конкретного запроса через все микросервисы. Помогает ответить на вопрос: «Где именно возникла задержка?».
- **Continuous Profiling (Непрерывное профилирование)** — анализ потребления ресурсов (CPU, RAM) на уровне строк кода в реальном времени.
- **Анализ сбоев (Error Analysis)** — автоматический сбор и группировка исключений (exceptions).

## </details>

---

<details>
<summary><span>26. Основные <b>метрики производительности</b></span></summary>
<br />

### **1. Метрики нагрузки и пропускной способности (Throughput)**

- **RPS (Requests Per Second)** — количество входящих запросов к серверу в секунду.
- **TPS (Transactions Per Second)** — количество успешно завершенных бизнес-операций (например, оплат или регистраций).
- **QPS (Queries Per Second)** — количество обращений к базе данных (обычно выше, чем RPS, так как один запрос может порождать несколько обращений к БД).

### **2. Метрики времени и качества (Latency & Reliability)**

- **Response Time (Время отклика)** — полное время обработки запроса. Важно смотреть на **перцентили**:
- **p50 (Медиана):** среднее время для обычного пользователя.
- **p99:** время, которое видят 1% пользователей с самыми медленными запросами (критично для SLA).

- **Error Rate (Уровень ошибок)** — доля ответов с кодами 4xx и 5xx. Резкий рост этой метрики — главный сигнал об аварии.

### **3. Метрики ресурсов (Utilization)**

- **Infrastructure:** загрузка CPU (процессор), RAM (память), Traffic (сетевой канал) и Disk I/O (чтение/запись на диск).
- **Runtime:** количество активных процессов/потоков (Threads) и интенсивность работы сборщика мусора (GC Pause).

### **4. Состояние очередей и доступность**

- **Queue Depth (Размер очередей):** количество запросов, ожидающих обработки. Рост очереди — предвестник роста _Response Time_.
- **Uptime / Downtime:** время доступности и простоя системы в процентах (например, "четыре девятки" — 99.99%).

</details>

---

<details>
<summary><span>27. Стек инструментов <b>Observability</b></span></summary>
<br />

Для каждой задачи в индустрии сложились свои стандарты (De Facto):

| Направление        | Инструменты (Stack)                       | Описание                                                                                       |
| ------------------ | ----------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **Мониторинг**     | **Prometheus** + Grafana                  | **Prometheus** — стандарт для сбора метрик (pull-модель). Grafana — для визуализации графиков. |
| **Логирование**    | **ELK** (Elasticsearch, Logstash, Kibana) | Logstash собирает, Elasticsearch хранит и ищет, Kibana показывает логи.                        |
| **Трейсинг**       | **Jaeger**, Zipkin                        | Позволяют увидеть «дерево» вызовов: как запрос прошел через 10 микросервисов.                  |
| **Профилирование** | **Pyroscope**, Parca                      | Показывают "Flame Graphs" — какие функции в коде едят больше всего CPU прямо сейчас.           |

</details>

---

<details>
<summary><span>28. <b>Виды баз данных</b> и их назначение</span></summary>
<br />

| Тип базы данных            | Популярные примеры                | Для чего лучше всего подходит (Use Case)                                                                                                    |
| -------------------------- | --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| **Реляционные (SQL)**      | PostgreSQL, MySQL, Oracle         | Данные со строгой структурой, где важны **транзакции (ACID)** и сложные связи. Идеально для финансовых систем и учетных записей.            |
| **Документарные**          | MongoDB, CouchDB                  | Хранение данных со слабой структурой (JSON-подобных). Подходит для каталогов товаров, профилей пользователей и быстрой итерации разработки. |
| **Поисковые движки**       | Elasticsearch, Solr, Meilisearch  | Полнотекстовый поиск, сложная фильтрация, автодополнение и аналитика логов.                                                                 |
| **Ключ-значение (K-V)**    | Redis, Memcached, etcd, Tarantool | **Кэширование**, хранение сессий, очередей или конфигураций. Работают максимально быстро (часто в RAM).                                     |
| **Колоночные (OLAP)**      | ClickHouse, Cassandra, Vertica    | **Аналитика больших данных**. Читают только нужные колонки, что ускоряет построение отчетов по миллиардам строк.                            |
| **Графовые**               | Neo4j, Memgraph                   | Данные с огромным количеством связей. Социальные сети (поиск друзей), рекомендательные системы, борьба с мошенничеством.                    |
| **Time Series**            | InfluxDB, VictoriaMetrics         | Данные, привязанные ко времени. Метрики систем, котировки акций, данные с датчиков (IoT).                                                   |
| **Blob Store (Объектные)** | Amazon S3, MinIO, Ceph            | Хранение **неструктурированных файлов**: видео, фото, бэкапы, статика сайтов.                                                               |

---

### **Короткая шпаргалка по выбору:**

1. **Нужны четкие связи и гарантии денег?** — Бери **Postgres**.
2. **Нужно быстро искать по тексту «синий пиджак»?** — Бери **Elasticsearch**.
3. **Нужно построить отчет «продажи за 5 лет по регионам»?** — Бери **ClickHouse**.
4. **Нужно быстро достать корзину пользователя по ID?** — Бери **Redis**.
5. **Нужно понять, через сколько рукопожатий знакомы два человека?** — Бери **Neo4j**.

</details>

---

<details>
<summary><span>29. <b>Поисковые движки</b> — это БД или надстройка?</span></summary>
<br />

### **1. Технически — это полноценная база данных**

Поисковые движки (например, **Elasticsearch**, **Solr**, **Meilisearch**) обладают всеми признаками СУБД:

- **Хранение:** Они записывают данные на диск в своем специфическом формате (инвертированный индекс).
- **Интерфейс:** У них есть API (обычно REST) или свой язык запросов для вставки, удаления и поиска данных.
- **Масштабируемость:** Они поддерживают кластеризацию, шардирование (разделение данных на части) и репликацию (копии для надежности).

### **2. Архитектурно — это чаще всего «надстройка»**

В большинстве систем поисковый движок не является основным хранилищем («Source of Truth»). Его используют как **вторичное хранилище** рядом с реляционной БД (PostgreSQL/MySQL):

- **Зачем:** Реляционные БД отлично справляются с транзакциями и связями, но очень медленно и плохо ищут по тексту (особенно с учетом опечаток, синонимов или весов).
- **Как это работает:** Данные сначала пишутся в основную БД, а затем синхронизируются с поисковым движком.

---

### **Внутреннее устройство: Инвертированный индекс**

Главное «волшебство», которое делает поисковик поисковиком — это способ организации данных.

- **В обычной БД (Row-based):** Данные хранятся строками. Чтобы найти слово «Apple» в колонке описания, базе нужно просканировать все строки (или использовать ограниченный B-Tree индекс).
- **В поисковике (Inverted Index):** Создается таблица, где ключом является **слово**, а значением — **список ID документов**, где оно встречается.
  > _Пример:_ > «Apple» -> [ID: 1, ID: 5, ID: 102]
  > «Smartphone» -> [ID: 5, ID: 20]
  > Поиск становится мгновенным, так как движок сразу знает, куда смотреть.

---

### **Когда использовать как единственную БД?**

Иногда поисковые движки используют без основной БД. Самый яркий пример — **ELK Stack (Elasticsearch, Logstash, Kibana)** для работы с логами:

- Логи записываются напрямую в Elasticsearch.
- Там они хранятся, индексируются и анализируются.
- Здесь не важны транзакции или сложные связи, поэтому Elasticsearch справляется сам.

</details>

---

<details>
<summary><span>30. От чего зависит <b>выбор базы данных?</b></span></summary>
<br />

### **1. Транзакции (ACID vs BASE)**

- Если в системе критически важна целостность (например, переводы денег), необходима БД с полной поддержкой **ACID**-транзакций (обычно реляционные БД).
- Если важнее высокая доступность и масштабируемость, можно рассмотреть NoSQL решения, работающие по модели **BASE**.

### **2. Характер и формат данных**

- **Формат данных:** Насколько данные структурированы? Для жестких схем подходят SQL, для гибких (JSON-like) — документоориентированные БД.
- **Частота изменяемости формата:** Если схема данных постоянно меняется (динамические атрибуты товаров), лучше выбрать **Schemaless** решение (например, MongoDB), чтобы не проводить тяжелые миграции таблиц при каждом обновлении кода.

### **3. Характер обращений к данным (Workload)**

- Нужно ли нам много мелких записей и чтений по ключу (OLTP)?
- Или мы будем делать тяжелые аналитические отчеты по миллиардам строк (OLAP)?
- От этого зависит, будет ли база **строковой** (Postgres) или **колоночной** (ClickHouse).

### **4. Экспертиза и сообщество**

- **Навык работы с технологией:** Насколько команда знакома с инструментом? Даже самая быстрая БД может стать тормозом, если никто не умеет её правильно настраивать и оптимизировать индексы.
- **Сообщество и зрелость технологии:** Насколько база проверена временем? Есть ли у неё развитое комьюнити, готовые библиотеки-драйверы и легко ли найти ответы на возникающие ошибки в Stack Overflow?

---

### **Резюме для архитектора**

Выбирая БД, задайте себе три вопроса:

1. Потеря данных или их временная неконсистентность допустимы?
2. Насколько часто будет меняться структура документа?
3. Есть ли у нас ресурсы (люди и время) на поддержку этой конкретной технологии?

</details>

---

<details>
<summary><span>31. Какие существуют <b>классы баз данных?</b></span></summary>
<br />

### **1. По типу нагрузки (OLTP vs OLAP vs HTAP)**

- **OLTP (Online Transactional Processing):** Ориентированы на огромное количество коротких транзакций (чтение/запись одной строки).

  > _Пример:_ PostgreSQL, MySQL. Используются для работы пользователей с приложением в реальном времени.

- **OLAP (Online Analytical Processing):** Оптимизированы для сложных аналитических запросов над большими объемами данных (агрегации, отчеты).

  > _Пример:_ ClickHouse, BigQuery. Хранят данные колонками.

- **HTAP (Hybrid Transactional/Analytical Processing):** «Две в одной». Позволяют выполнять аналитические запросы прямо на транзакционных данных без задержек на копирование.
  > _Пример:_ TiDB, MemSQL.

---

### **2. По способу размещения и работы**

- **Embedded (Встраиваемые):** Работают внутри процесса самого приложения, не требуют отдельного сервера.

  > _Пример:_ SQLite, H2. Идеальны для мобильных приложений или локального кэширования.

- **Single File Database:** Вся база данных физически представляет собой один файл на диске.

  > _Пример:_ SQLite. Удобно для переноса и простых приложений.

- **Distributed (Распределенные):** Данные физически разнесены по многим серверам (узлам), что обеспечивает масштабируемость и отказоустойчивость.
  > _Пример:_ Cassandra, CockroachDB.

---

### **3. По среде хранения (Storage Medium)**

- **In-memory:** Все данные хранятся в оперативной памяти (RAM). Это дает экстремальную скорость, но данные могут пропасть при выключении питания (если нет механизма снимков на диск).

  > _Пример:_ Redis, Memcached, SAP HANA.

- **Persistent (Постоянные):** Данные хранятся на энергонезависимых носителях (HDD/SSD). Главный приоритет — сохранность данных при перезагрузке.
  > _Пример:_ Большинство классических БД (Oracle, MSSQL).

---

### **Резюме для выбора:**

| Если нужно...                               | Выбирай класс...           |
| ------------------------------------------- | -------------------------- |
| **Максимальный RPS и низкий Latency**       | **In-memory**              |
| **Построить отчет по миллиарду продаж**     | **OLAP**                   |
| **Хранить данные в мобильном приложении**   | **Embedded / Single file** |
| **Обрабатывать заказы в интернет-магазине** | **OLTP / Persistent**      |

</details>

---

<details>
<summary><span>32. <b>Индексы:</b> что это, зачем нужны и какие у них особенности?</span></summary>
<br />

### **Что это такое?**

**Индекс** — это вспомогательная структура данных (обычно дерево или хеш-таблица), которая хранит значения одного или нескольких столбцов таблицы и ссылки на соответствующие строки. Вместо того чтобы перебирать миллион записей по порядку, база данных обращается к индексу и за несколько шагов находит нужный результат.

---

### **Зачем они нужны?**

Главная и единственная цель — **ускорение чтения**. Без индекса база данных вынуждена выполнять **Full Table Scan** (полное сканирование таблицы), что на больших объемах данных занимает критически много времени.

---

### **Ключевые особенности и «цена» использования**

Индексы — это не «бесплатное» ускорение. У них есть три важные особенности, которые нужно учитывать при проектировании:

1. **Ускоряют чтение:** Позволяют выполнять поиск, фильтрацию (`WHERE`) и сортировку (`ORDER BY`) на порядки быстрее.
2. **Замедляют запись:** Это главный минус. При каждой операции `INSERT`, `UPDATE` или `DELETE` база данных должна не только изменить саму таблицу, но и **обновить все связанные индексы**. Чем больше индексов на таблице, тем медленнее в нее пишутся данные.
3. **Используют дополнительную память:** Индексы — это отдельные объекты, которые занимают место на диске и (в идеале) в оперативной памяти. В некоторых случаях размер всех индексов может превышать размер самих данных в таблице.

---

### **Когда использовать (Best Practices):**

- Создавайте индексы для колонок, которые часто участвуют в условиях поиска (`WHERE`).
- Индексируйте колонки, по которым часто происходит объединение таблиц (`JOIN`).
- Избегайте создания индексов для колонок с очень низкой селективностью (например, пол «мужской/женский»), так как базе будет проще прочитать всю таблицу.
- Удаляйте неиспользуемые индексы, чтобы не замедлять запись зря.

</details>

---

<details>
<summary><span>33. Какие бывают <b>типы индексов?</b></span></summary>
<br />

### **1. B-Tree (Balanced Tree)**

Самый универсальный и используемый по умолчанию тип индекса в большинстве БД.

- **Как работает:** Данные хранятся в виде сбалансированного дерева, где в узлах находятся значения, а в листьях — ссылки на строки.
- **Для чего:** Операции сравнения (`=`, `>`, `<`, `>=`) и поиск по диапазону (`BETWEEN`).
- **Особенность:** Поддерживает сортировку данных.

---

### **2. Hash Index**

- **Как работает:** Применяет хеш-функцию к значению колонки и сопоставляет его с адресом строки.
- **Для чего:** Только для поиска по точному совпадению (`=`, `IN`).
- **Плюсы:** Работает быстрее B-Tree при поиске по конкретному значению.
- **Минусы:** Не умеет искать по диапазонам и не поддерживает сортировку.

---

### **3. Bitmap Index**

- **Как работает:** Создает битовую маску (0 и 1) для каждого уникального значения в колонке.
- **Для чего:** Колонки с низкой селективностью (где мало уникальных значений: пол, статус заказа, регион).
- **Плюсы:** Занимает очень мало места и позволяет мгновенно объединять условия через логические `AND`/`OR`.

---

### **4. GIST и GIN (Специализированные)**

- **GIN (Generalized Inverted Index):** «Инвертированный индекс». Идеален для поиска внутри составных объектов (массивы, JSONB, полнотекстовый поиск).
- **GiST (Generalized Search Tree):** Используется для индексации геометрических данных (координаты) и поиска «ближайших соседей».

---

### **5. Другие виды (по логике применения)**

- **Кластерный индекс (Clustered):** Определяет физический порядок хранения строк в таблице. У таблицы может быть только один такой индекс (обычно это Primary Key).
- **Покрывающий индекс (Covering):** Индекс, который содержит в себе все поля, запрошенные в `SELECT`. Базе не нужно обращаться к самой таблице, она берет всё из индекса.
- **Составной индекс (Composite):** Индекс по нескольким колонкам сразу. Важен порядок: индекс `(A, B)` поможет при поиске по `A` или `A+B`, но будет бесполезен при поиске только по `B`.
- **Частичный индекс (Partial):** Индекс не по всей таблице, а по условию.
  > _Пример:_ Индексировать только активные заказы `WHERE status = 'active'`. Это экономит память.

**Шпаргалка:**

- Нужно искать по числу или дате? — **B-Tree**.
- Нужно искать по координатам на карте? — **GiST**.
- Нужно искать теги в JSON? — **GIN**.
- Нужно быстро находить по точному ID? — **Hash**.

</details>

---

<details>
<summary><span>34. Что такое <b>транзакции?</b></span></summary>
<br />

**Транзакция** — это логическая единица работы с базой данных, представляющая собой последовательность операций (чтение, запись), которая выполняется как единое целое.

### **Главный принцип: «Всё или ничего»**

Если хотя бы одна операция внутри транзакции завершается ошибкой, все предыдущие изменения отменяются (**rollback**), и база данных возвращается в исходное состояние. Если всё прошло успешно, изменения фиксируются на постоянной основе (**commit**).

---

### **Зачем это нужно?**

Транзакции решают две главные проблемы:

1. **Отказоустойчивость:** Гарантируют, что при сбое (например, банковского перевода) деньги не «зависнут» в воздухе.
2. **Параллелизм:** Позволяют тысячам пользователей одновременно менять одни и те же данные без риска их испортить.

</details>

---

<details>
<summary><span>35. Свойства <b>ACID</b></span></summary>
<br />

### **1. Atomicity — Атомарность («Всё или ничего»)**

Транзакция является неделимой единицей.

- Если в транзакции 10 шагов и 9 прошли успешно, а 10-й упал — **отменяются все 10**.
- Система никогда не зафиксирует «половинчатый» результат.
- Инструмент реализации: **Undo Log** (журнал отката).

### **2. Consistency — Согласованность**

Транзакция переводит базу из одного валидного состояния в другое.

- Все правила (Constraints), такие как уникальность ключей, внешние ключи (Foreign Keys) и проверки (Checks), должны соблюдаться.
- Если транзакция нарушает логику базы (например, вставляет строку без обязательного поля), база её отклонит.

### **3. Isolation — Изоляция**

Параллельные транзакции не должны влиять друг на друга.

- Если два пользователя одновременно меняют один и тот же баланс, результат должен быть таким, будто они это делали строго по очереди.
- Изоляция регулируется **уровнями изоляции** (от самого слабого до самого строгого — Serializable).
- Инструмент реализации: **Блокировки (Locks)** и **MVCC** (многоверсионность).

### **4. Durability — Долговечность (Стойкость)**

Если пользователь получил подтверждение `COMMIT`, данные записаны «навечно».

- Даже если сразу после нажатия кнопки «Оплатить» на сервере выключится электричество или упадет ОС, после перезагрузки данные будут на месте.
- Инструмент реализации: **Redo Log** (журнал упреждающей записи) или **WAL** (Write-Ahead Logging).

---

### **Шпаргалка для запоминания:**

- **A** — Не делай половину работы.
- **C** — Не ломай правила базы.
- **I** — Не подсматривай за другими.
- **D** — Не теряй то, что сохранил.

</details>

---

<details>
<summary><span>36. Что такое <b>Constraints</b> и зачем нужны <b>Deferrable Transactions?</b></span></summary>
<br />

### **1. Constraints (Ограничения целостности)**

Это правила, которые не позволяют записать в базу некорректные данные. Они напрямую обеспечивают свойство **Consistency** в ACID.

- **NOT NULL:** запрещает пустые значения.
- **UNIQUE:** гарантирует уникальность значений в колонке.
- **PRIMARY KEY:** уникальный идентификатор строки (Unique + Not Null).
- **FOREIGN KEY:** проверяет, что ссылка ведет на существующую запись в другой таблице.
- **CHECK:** проверяет условие (например, `age > 18` или `price > 0`).

---

### **2. Deferrable Constraints (Откладываемые проверки)**

Обычно база данных проверяет констрейнты **немедленно** после выполнения каждой строки кода. Но в сложных транзакциях это может вызвать ошибку.

**Проблема:** Вам нужно поменять местами значения в колонке с уникальным индексом. В процессе замены на мгновение возникнет дубликат, и база выдаст ошибку, не дав завершить транзакцию.

**Решение: Deferrable Transactions**
Вы можете пометить ограничение как `DEFERRABLE` (откладываемое). Это позволяет перенести проверку правил с момента выполнения команды на **самый конец транзакции** (перед `COMMIT`).

### **Режимы проверок:**

- **Immediate (Немедленно):** проверка после каждой команды (стандартное поведение).
- **Deferred (Отложено):** проверка всех правил только в момент фиксации транзакции. Если в конце транзакции данные всё еще нарушают правила — произойдет откат.

---

### **Зачем это объединять?**

Использование **отложенных констрейнтов** внутри транзакций критически важно для:

1. **Циклических зависимостей:** когда Таблица А ссылается на Б, а Б на А. Вы не сможете вставить данные ни в одну из них без временного отключения проверок.
2. **Массовых обновлений:** когда в середине процесса данные временно неконсистентны, но к концу транзакции они приходят в норму.

</details>

---

<details>
<summary><span>37. Какие существуют <b>аномалии транзакций?</b></span></summary>
<br />

### **1. Потерянное обновление (Lost Update)**

Происходит, когда две транзакции одновременно читают одно и то же значение, изменяют его и записывают обратно. В итоге вторая транзакция просто «затирает» изменения первой.

- **Пример:** Баланс 100$. Юзер А хочет прибавить 50$, Юзер Б хочет прибавить 20$. Оба считали «100». Юзер А записал «150», а Юзер Б следом записал «120». 50$ от Юзера А просто пропали.

### **2. Грязное чтение (Dirty Read)**

Транзакция читает данные, которые были изменены другой транзакцией, которая еще **не зафиксирована (не сделала commit)**.

- **Пример:** Юзер А переводит деньги и обновил баланс (но еще не подтвердил). Юзер Б считал этот «новый» баланс. Юзер А отменил транзакцию (Rollback). Теперь у Юзера Б на руках данные, которых в базе официально никогда не было.

### **3. Неповторяющееся чтение (Non-repeatable Read)**

Внутри одной транзакции вы дважды читаете **одну и ту же строку**, но между чтениями другая транзакция успевает её **изменить или удалить**.

- **Пример:** Вы считали цену товара (100$). Пока вы думали, другая транзакция изменила её на 200$. Вы читаете ту же строку снова, а цена уже другая. Данные «уплыли» прямо во время вашей работы.

### **4. Фантомное чтение (Phantom Read)**

Внутри одной транзакции вы делаете запрос по диапазону (например, «все заказы за сегодня»), а в это время другая транзакция делает **INSERT** новой строки, подходящей под ваше условие.

- **Пример:** Вы считали количество заказов (их было 10). Пока вы формировали отчет, кто-то добавил еще один заказ. Вы пересчитываете, и их уже 11. Появился «фантом», которого не было в начале.

---

### **Сводная таблица аномалий:**

| Аномалия           | Суть проблемы                      | Объект влияния         |
| ------------------ | ---------------------------------- | ---------------------- |
| **Lost Update**    | Запись поверх чужой записи.        | Строка (запись)        |
| **Dirty Read**     | Чтение незафиксированных данных.   | Строка (состояние)     |
| **Non-repeatable** | Изменение значения между чтениями. | Та же самая строка     |
| **Phantom Read**   | Появление новых строк в выборке.   | Набор строк (диапазон) |

</details>

---

<details>
<summary><span>38. <b>Уровни изоляции</b> транзакций</span></summary>
<br />

### **1. Read Uncommitted (Чтение незафиксированных данных)**

Самый слабый уровень. Транзакции могут видеть изменения, которые еще не были зафиксированы (`commit`) другими транзакциями.

- **Допускает аномалии:** Грязное чтение, Неповторяющееся чтение, Фантомное чтение.
- **Плюсы:** Максимальная скорость.
- **Применяется:** Там, где точность не важна (например, примерный счетчик лайков).

### **2. Read Committed (Чтение зафиксированных данных)**

Уровень по умолчанию во многих БД (например, PostgreSQL). Транзакция видит только те данные, которые были зафиксированы до начала чтения.

- **Защищает от:** Грязного чтения.
- **Допускает аномалии:** Неповторяющееся чтение, Фантомное чтение.
- **Как работает:** Каждый запрос `SELECT` внутри транзакции видит свежий «снимок» зафиксированных данных.

### **3. Repeatable Read (Повторяющееся чтение)**

Гарантирует, что если вы прочитали строку, то при повторном чтении она будет точно такой же.

- **Защищает от:** Грязного чтения, Неповторяющегося чтения.
- **Допускает аномалии:** Фантомное чтение (в некоторых БД, например в MySQL/InnoDB, этот уровень также защищает и от фантомов).
- **Как работает:** Транзакция видит «снимок» данных на момент своего **начала**.

### **4. Serializable (Сериализуемость)**

Самый строгий уровень. Транзакции выполняются так, будто они идут строго друг за другом.

- **Защищает от:** Всех аномалий (включая Фантомное чтение).
- **Минусы:** Самая низкая производительность. Часто возникают ошибки блокировок (Deadlocks) или ошибки сериализации, требующие повторного выполнения транзакции.

---

### **Сводная таблица соответствия:**

| Уровень изоляции     | Грязное чтение | Неповторяющееся чтение | Фантомное чтение |
| -------------------- | -------------- | ---------------------- | ---------------- |
| **Read Uncommitted** | Допустимо      | Допустимо              | Допустимо        |
| **Read Committed**   | **Защищено**   | Допустимо              | Допустимо        |
| **Repeatable Read**  | **Защищено**   | **Защищено**           | Допустимо        |
| **Serializable**     | **Защищено**   | **Защищено**           | **Защищено**     |

На практике большинство разработчиков останавливаются на **Read Committed**, так как это золотая середина между скоростью и целостностью.

</details>

---

<details>
<summary><span>39. Механизмы БД: <b>2PL, MVCC и WAL</b></span></summary>
<br />

### **1. 2PL (Two-Phase Locking — Двухфазная блокировка)**

Это классический способ обеспечить **Изоляцию (Isolation)** через блокировки.

- **Суть:** Транзакция не может просто так менять данные. Она должна сначала захватить «замок» (lock) на строку.
- **Две фазы:**

1. **Фаза расширения:** Транзакция только захватывает блокировки и не отпускает их.
2. **Фаза сжатия:** Транзакция начинает отпускать блокировки (обычно в самом конце) и больше не может брать новые.

- **Минус:** Читатели ждут писателей, а писатели ждут читателей. Это сильно замедляет систему.

---

### **2. MVCC (Multi-Version Concurrency Control)**

Современный и более быстрый подход к изоляции (используется в Postgres, MySQL InnoDB).

- **Суть:** Вместо того чтобы блокировать строку, база создает её **новую версию**.
- **Главный плюс:** Читатели никогда не блокируют писателей, а писатели не блокируют читателей.
- **Как это работает:** Когда транзакция «А» меняет строку, она создает копию. Транзакция «Б», которая в это время читает данные, видит старую версию строки («снимок»), пока транзакция «А» не сделает `commit`.

---

### **3. WAL (Write-Ahead Logging — Журнал упреждающей записи)**

Механизм обеспечения **Долговечности (Durability)**.

- **Проблема:** Записывать данные в файлы таблиц сразу — это долго (нужно искать место на диске, обновлять индексы). Если сервер упадет в процессе, данные испортятся.
- **Решение:** Сначала все изменения записываются в простой текстовый лог-файл (WAL) последовательно (это очень быстро).
- **Результат:** Даже если база «упадет» до того, как успеет обновить основные таблицы, при перезагрузке она просто прочитает WAL и «проиграет» все подтвержденные транзакции заново.

---

### **Как они работают вместе?**

1. **MVCC** позволяет нам одновременно читать и писать без тормозов.
2. **2PL** (или его элементы) используется там, где нужно гарантированно избежать конфликтов при записи в одну строку.
3. **WAL** гарантирует, что даже при самом страшном сбое результаты работы MVCC и 2PL не пропадут.

</details>

---

<details>
<summary><span>40. Что такое <b>BASE</b> (для NoSQL БД)?</span></summary>
<br />

**BASE** — это модель проектирования баз данных, которая является противоположностью строгому **ACID**. Она используется в распределенных NoSQL системах, где важнее обеспечить доступность и скорость работы на огромных объемах данных, чем мгновенную точность.

### **Расшифровка аббревиатуры:**

- **Basically Available (Базовая доступность):**
  Система гарантирует ответ на любой запрос, но он может быть неудачным или содержать не самые свежие данные. Главное — база продолжает работать, даже если часть узлов недоступна.
- **Soft-state (Неустойчивое состояние):**
  Состояние данных может меняться со временем само по себе (без новых запросов) из-за фоновой синхронизации между серверами.
- **Eventually Consistent (Согласованность в конечном счете):**
  Данные на разных серверах могут отличаться прямо сейчас, но система гарантирует, что со временем они синхронизируются и станут идентичными (если прекратить запись).

---

### **Сравнение: ACID против BASE**

| Характеристика      | ACID (SQL)                            | BASE (NoSQL)                        |
| ------------------- | ------------------------------------- | ----------------------------------- |
| **Приоритет**       | Целостность и точность.               | Скорость и масштабируемость.        |
| **Согласованность** | Немедленная (Strong Consistency).     | Отложенная (Eventual Consistency).  |
| **Сложность**       | Трудно масштабировать на много узлов. | Легко масштабируется горизонтально. |
| **Пример**          | Банковский перевод, склад.            | Лента соцсетей, лайки, логи.        |

---

### **Зачем это нужно?**

В гигантских системах (Amazon, Facebook) невозможно заставить тысячи серверов договориться о значении каждой записи мгновенно — это бы «подвесило» интернет. Поэтому они выбирают **BASE**: пользователь может увидеть старый комментарий или неверное число лайков на долю секунды, зато сайт будет работать молниеносно.

</details>

---

<details>
<summary><span>41. Объекты баз данных: <b>Процедуры, Триггеры, View, Watch API</b></span></summary>
<br />

### **1. Хранимые процедуры (Stored Procedures)**

Это фрагменты кода (функции), которые хранятся и выполняются прямо внутри базы данных.

- **Зачем:** Чтобы не гонять большие объемы данных в приложение и обратно. Логика выполняется максимально близко к данным.
- **Плюсы:** Снижение сетевого трафика и возможность централизованно менять логику для всех приложений сразу.

### **2. Триггеры (Triggers)**

Специальные процедуры, которые **автоматически** запускаются при наступлении определенного события в таблице.

- **События:** `INSERT`, `UPDATE`, `DELETE`.
- **Пример:** При удалении пользователя триггер автоматически запишет информацию об этом в таблицу логов или удалит все его связанные заказы.

### **3. Материализованные представления (Materialized View)**

В отличие от обычного View (которое является просто сохраненным запросом), материализованное представление **физически сохраняет результат** запроса на диск.

- **Зачем:** Для тяжелых аналитических отчетов. Вместо того чтобы каждый раз считать сумму по миллиону строк, база один раз сохраняет результат и отдает его мгновенно.
- **Минус:** Данные в «материалке» устаревают. Их нужно периодически обновлять (`REFRESH`).

### **4. Watch API (Change Data Capture)**

Механизм (характерный для K-V хранилищ вроде **etcd** или **Redis**, а также современных SQL БД), который позволяет приложению «подписаться» на изменения ключа или таблицы.

- **Как работает:** Приложение открывает соединение, и как только данные меняются, база сама присылает уведомление (push).
- **Пример:** В системе конфигураций (etcd) микросервис «ждет» изменения настроек и мгновенно их применяет без перезагрузки.

---

### **Сводная таблица применения:**

| Объект                | Когда использовать?                                           |
| --------------------- | ------------------------------------------------------------- |
| **Процедура**         | Нужно выполнить сложный расчет внутри БД.                     |
| **Триггер**           | Нужно автоматически поддерживать целостность или логирование. |
| **Materialized View** | Нужно мгновенно открывать отчет, который долго считается.     |
| **Watch API**         | Нужно сразу узнать, что данные изменились (реактивность).     |

</details>

---

<details>
<summary><span>42. <b>Брокеры сообщений:</b> зачем они нужны?</span></summary>
<br />

Брокеры сообщений (Message Brokers) — это промежуточное программное обеспечение, которое позволяет различным сервисам общаться друг с другом, даже если они написаны на разных языках или работают с разной скоростью.

### **Основные задачи и преимущества**

- **Буферизация (Smoothing):**
  Брокер выступает в роли «накопителя». Если на систему внезапно обрушился поток запросов, брокер сохраняет их в очередь, позволяя сервисам-обработчикам забирать задачи постепенно, не падая от перегрузки.
- **Асинхронная связь:**
  Отправителю не нужно ждать, пока получатель обработает сообщение. Он просто «выстрелил» данными в брокер и пошел дальше. Это критично для отзывчивости интерфейсов.
- **Слабое связывание (Decoupling):**
  Сервисы ничего не знают друг о друге, они знают только о брокере. Это позволяет менять, обновлять или масштабировать один сервис, не ломая работу остальных.
- **Масштабируемость:**
  Легко добавить больше «потребителей» (workers), которые будут разгребать очередь из брокера параллельно.
- **Отказоустойчивость:**
  Если сервис-получатель «упал», сообщения не пропадут. Они будут лежать в брокере до тех пор, пока сервис не поднимется и не заберет их.
- **Понимание потоков данных:**
  Брокеры позволяют выстраивать сложные цепочки обработки (Data Pipelines), где данные проходят через несколько стадий трансформации и анализа.

---

### **Пример из жизни:**

Представь оформление заказа в интернет-магазине.

1. Ты нажал «Купить».
2. Основной сервис быстро сохранил заказ и ответил тебе «Ок».
3. Он кинул сообщение в брокер.
4. А уже из брокера другие сервисы **асинхронно** забирают задачу: один шлет письмо на почту, другой списывает товар со склада, третий готовит чек.

</details>

---

<details>
<summary><span>43. Как устроены <b>Kafka</b> и <b>RabbitMQ</b>: основные отличия</span></summary>
<br />

Хотя оба инструмента работают с сообщениями, они делают это по-разному: RabbitMQ — это классическая «умная» очередь, а Kafka — это распределенный «лог» событий.

### **1. Устройство Apache Kafka**

Kafka работает по принципу распределенного журнала транзакций. Сообщения не удаляются сразу после прочтения, а хранятся заданное время.

- **Producer (Писатель):** Отправляет данные в систему.
- **Consumer (Читатель):** Забирает данные. Читатели сами следят за тем, на каком месте в логе они остановились.
- **Broker:** Один узел (сервер) кластера Kafka.
- **Topic (Топик):** Логическая очередь или категория, в которую группируются сообщения.
- **Partition (Партиция):** Физическая часть очереди. Топик делится на части для параллельной обработки и масштабируемости.

---

### **2. Устройство RabbitMQ**

RabbitMQ — это брокер, который берет на себя всю логику маршрутизации сообщений.

- **Producer:** Отправляет сообщение в **Exchange**.
- **Exchange (Обменник):** «Мозг» системы. Он принимает сообщения и на основе правил (routing keys) решает, в какую очередь их направить.
- **Queue (Очередь):** Хранилище, где сообщения лежат до момента прочтения.
- **Consumer:** Получает сообщения из очереди (часто через **Push**-модель, когда брокер сам «выталкивает» данные в потребителя).

---

### **3. Ключевые отличия**

| Характеристика      | RabbitMQ                                                                      | Apache Kafka                                                                             |
| ------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |
| **Модель работы**   | **Умный брокер / Глупый потребитель**. Брокер следит за состоянием сообщений. | **Глупый брокер / Умный потребитель**. Читатель сам управляет своим указателем (offset). |
| **Хранение данных** | Сообщения удаляются сразу после подтверждения обработки потребителем.         | Сообщения хранятся в логах долгое время (даже после прочтения).                          |
| **Приоритет**       | Сложная маршрутизация и гарантия доставки.                                    | Огромная пропускная способность и работа с потоками данных в реальном времени.           |
| **Перечитывание**   | Невозможно (сообщения уже нет).                                               | Возможно (можно «отмотать» время назад и перечитать лог).                                |

### **Что выбрать?**

- **RabbitMQ:** Если нужна сложная логика доставки (например, разным сервисам нужны разные части данных) или если важна моментальная обработка отдельных задач.
- **Kafka:** Если нужно обрабатывать миллионы событий в секунду, строить аналитику на лету или иметь возможность перечитать историю данных.

</details>

---

<details>
<summary><span>44. Модели <b>Push</b> и <b>Pull</b> в брокерах</span></summary>
<br />

Модели **Push** и **Pull** определяют, кто является инициатором передачи данных: брокер, который «выталкивает» сообщение в сервис, или сервис, который сам «приходит» за данными.

### **1. Push-модель (Инициатор — Брокер)**

Брокер сам отправляет сообщения потребителям (Consumers), как только они появляются в очереди.

- **Как работает:** Потребитель устанавливает соединение, и брокер «выталкивает» в него данные по мере их поступления.
- **Плюсы:** Минимальная задержка (latency) — данные доставляются мгновенно.
- **Минусы:** Риск перегрузки потребителя (заваливание данными), если он не справляется с темпом брокера. Требуется механизм контроля потока (Backpressure).
- **Пример:** **RabbitMQ** использует Push-модель (хотя поддерживает и Pull).

---

### **2. Pull-модель (Инициатор — Потребитель)**

Потребитель сам запрашивает (опрашивает) брокер на наличие новых сообщений.

- **Как работает:** Потребитель посылает запрос: «Дай мне следующие 100 сообщений». Если данных нет, он может подождать или прийти позже.
- **Плюсы:** Потребитель сам контролирует скорость обработки и никогда не будет перегружен. Легко реализовать пакетную обработку (batching).
- **Минусы:** Может возникнуть задержка, если потребитель опрашивает брокер слишком редко.
- **Пример:** **Kafka** работает по Pull-модели.

---

### **Короткое сравнение для Kafka и RabbitMQ:**

| Брокер       | Модель   | Логика                                                                          |
| ------------ | -------- | ------------------------------------------------------------------------------- |
| **RabbitMQ** | **Push** | Брокер «заботится» о потребителе и отправляет ему задачи сам.                   |
| **Kafka**    | **Pull** | Потребитель «умный»: он сам решает, когда и сколько данных ему забрать из лога. |

</details>

---

<details>
<summary><span>45. Надежность в брокерах: <b>Data Retention</b> и <b>Гарантии доставки</b></span></summary>
<br />

### **1. Data Retention (Удержание данных)**

Это политика, определяющая, как долго сообщения остаются в брокере.

- **В RabbitMQ:** По умолчанию сообщение удаляется сразу после того, как потребитель прислал подтверждение (`Ack`) об успешной обработке.
- **В Kafka:** Сообщения хранятся в течение заданного времени (например, 7 дней) или пока не будет достигнут лимит по объему диска. Это позволяет перечитывать данные заново.

---

### **2. Гарантии доставки (Delivery Semantics)**

Когда мы отправляем сообщение через брокер, существует три основных сценария того, как оно дойдет до получателя:

- **At most once (Не более одного раза):**
  Сообщение отправляется один раз. Если произошел сбой сети или сервиса — оно теряется.

  > _Результат:_ Либо 0, либо 1 доставка. Дубликатов нет, но возможны потери.

- **At least once (Хотя бы один раз):**
  Самый распространенный режим. Отправитель будет слать сообщение до тех пор, пока не получит подтверждение. Если подтверждение потерялось, сообщение придет снова.

  > _Результат:_ 1 и более доставок. Данные не теряются, но **возможны дубликаты**, которые система должна уметь обрабатывать.

- **Exactly once (Ровно один раз):**
  Самый сложный и дорогой в реализации уровень. Система гарантирует, что сообщение будет обработано потребителем ровно один раз, несмотря на сбои.
  > _Результат:_ Строго 1 доставка. Это требует сложной координации (транзакций) между брокером и приложением.

---

### **Резюме для выбора:**

| Гарантия          | Потеря данных | Дубликаты | Применение                                            |
| ----------------- | ------------- | --------- | ----------------------------------------------------- |
| **At most once**  | Возможна      | Исключены | Сбор логов, метрик (где потеря 1% не критична).       |
| **At least once** | Исключена     | Возможны  | Оплата, заказы (обработка должна быть идемпотентной). |
| **Exactly once**  | Исключена     | Исключены | Критичные финансовые расчеты в реальном времени.      |

</details>

---

<details>
<summary><span>46. Альтернативные способы хранения: <b>Client-side</b> и <b>CDN</b></span></summary>
<br />

### **1. Хранение на стороне клиента (Client-side Storage)**

Вместо того чтобы запрашивать всё с сервера, часть данных можно хранить прямо в браузере пользователя.

- **Cookies:** Маленькие объемы данных (до 4 КБ). Обычно используются для хранения идентификаторов сессий и токенов авторизации.
- **Local Storage:** Позволяет хранить до 5-10 МБ данных без срока действия. Данные сохраняются даже после закрытия браузера. Подходит для настроек темы, черновиков или корзины.
- **Session Storage:** Аналог Local Storage, но данные стираются при закрытии вкладки.
- **IndexedDB:** Полноценная встроенная NoSQL база данных в браузере для хранения больших объемов структурированных данных и файлов.

**Зачем это нужно:**

1. **Offline-режим:** Приложение может работать без интернета.
2. **Скорость:** Мгновенный доступ к данным без сетевых задержек.
3. **Экономия:** Снижение количества запросов к вашему API.

---

### **2. CDN (Content Delivery Network)**

**CDN** — это географически распределенная сеть серверов, предназначенная для быстрой доставки «тяжелого» статического контента.

- **Что хранится:** Изображения, видео, файлы стилей (CSS), скрипты (JS), шрифты.
- **Как это работает:** Когда пользователь запрашивает файл, CDN отдает его с ближайшего к нему сервера (Edge Server). Если вы в Москве, файл придет из московского дата-центра, а не из США.
- **Caching:** CDN кэширует контент. Вам не нужно отдавать одну и ту же картинку миллион раз — CDN сделает это за вас.

**Зачем это нужно:**

1. **Ускорение загрузки:** Уменьшается физическое расстояние, которое проходят данные (снижается пинг).
2. **Снятие нагрузки:** Основной сервер (Origin) занимается только бизнес-логикой, а не раздачей картинок.
3. **Отказоустойчивость:** Если один сервер CDN упадет, трафик перехватит другой ближайший узел.

---

### **Сравнение способов:**

| Способ          | Где храним?           | Что храним?                 | Главная цель               |
| --------------- | --------------------- | --------------------------- | -------------------------- |
| **Client-side** | Браузер пользователя  | Токены, настройки, кэш API  | UX и работа offline        |
| **CDN**         | Сеть серверов по миру | Картинки, видео, статика    | Скорость загрузки для всех |
| **Database**    | Ваш сервер / Облако   | Бизнес-данные, пользователи | Целостность и поиск        |

</details>

---

<details>
<summary><span>47. Какие существуют <b>гарантии доставки</b> сообщений?</span></summary>
<br />

В распределенных системах и брокерах сообщений выделяют три основных уровня гарантий:

### **1. At most once (Не более одного раза)**

Это самая простая и производительная модель, но наименее надежная.

- **Суть:** Сообщение отправляется один раз и не переотправляется в случае ошибки.
- **Результат:** Сообщение либо доставлено один раз, либо **потеряно**.
- **Применение:** Сбор метрик или логов, где потеря единичного сообщения не критична для системы.

### **2. At least once (Хотя бы один раз)**

Самая популярная модель в современных архитектурах.

- **Суть:** Отправитель ждет подтверждения (ACK) от получателя. Если подтверждение не пришло из-за сбоя, сообщение отправляется **повторно**.
- **Результат:** Сообщение будет доставлено как минимум один раз, но возможны **дубликаты**.
- **Применение:** Финансовые операции, заказы. Требует _идемпотентности_ на стороне получателя (чтобы повторная обработка того же заказа не привела к двойному списанию).

### **3. Exactly once (Ровно один раз)**

Самая сложная в реализации и «дорогая» по ресурсам модель.

- **Суть:** Система гарантирует, что сообщение будет доставлено и обработано **строго один раз**.
- **Результат:** Исключены и потери, и дубликаты.
- **Применение:** Критически важные системы, где дублирование недопустимо, а идемпотентность сложно реализовать на уровне кода.

</details>

---

<details>
<summary><span>48. <b>Репликация</b> против <b>Бэкапа</b></span></summary>
<br />

### **1. Репликация (Replication)**

Это процесс копирования данных с одного сервера (Master) на другой (Slave/Replica) в режиме реального времени или с минимальной задержкой.

- **Зачем нужна:**
- **Отказоустойчивость (High Availability):** Если основной сервер «упадет», система быстро переключится на реплику, и пользователи не заметят сбоя.
- **Масштабирование чтения:** Можно перенести тяжелые `SELECT` запросы на реплики, разгрузив основной сервер.

- **Главный минус:** Если вы случайно выполните `DROP TABLE` или `DELETE` без фильтра на мастере, эта ошибка **мгновенно применится и на всех репликах**. Репликация копирует все изменения, включая вредоносные.

---

### **2. Бэкап (Backup)**

Это «снимок» (snapshot) состояния базы данных в определенный момент времени (например, вчера в 02:00), который хранится отдельно.

- **Зачем нужен:**
- **Восстановление после человеческой ошибки:** Если данные были случайно удалены или испорчены кодом, бэкап — единственный способ вернуться в прошлое.
- **Защита от вирусов-шифровальщиков:** Бэкапы позволяют восстановить систему после кибератаки.
- **Аудит и история:** Можно посмотреть, какими данные были месяц назад.

- **Главный минус:** Восстановление из бэкапа занимает время (от минут до часов), в течение которого система может быть недоступна.

---

### **Разница: Краткая таблица**

| Характеристика       | Репликация                     | Бэкап                               |
| -------------------- | ------------------------------ | ----------------------------------- |
| **Цель**             | Доступность (чтобы не лежало). | Сохранность (чтобы не потерялось).  |
| **Актуальность**     | Данные «прямо сейчас».         | Данные на момент создания снимка.   |
| **Защита от ошибки** | Нет (ошибка копируется сразу). | Да (можно откатиться назад).        |
| **Нагрузка**         | Постоянная на сеть и диск.     | Разовая (в момент создания архива). |

### **Зачем нужен бэкап, если есть репликация?**

Репликация спасает от **поломки железа** (сгорел диск), но она беспомощна против **логических ошибок**. Если программист запустит кривой скрипт, который обнулит балансы всех пользователей, репликация послушно обнулит их на всех серверах. Бэкап — это ваш единственный «шанс на спасение», позволяющий восстановить данные до момента запуска этого скрипта.

> **Золотое правило:** Репликация — это для бизнеса, Бэкап — это для жизни. Нужно иметь и то, и другое.

</details>

---

<details>
<summary><span>49. Роли в репликации: <b>Master-Slave, Master-Master, Leaderless</b></span></summary>
<br />

### **1. Master-Slave (Single Leader)**

Самая популярная схема. Есть один главный узел (Master), который принимает записи, и несколько подчиненных (Slaves/Replicas), которые только отдают данные на чтение.

- **Преимущества:**
- Простота: нет конфликтов при записи, так как «хозяин» один.
- Легкое масштабирование чтения (просто добавь больше реплик).

- **Недостатки:**
- Сложность при падении мастера: нужно выбирать нового (Election), в это время запись невозможна.
- Задержка репликации: данные на слейве могут быть чуть старее, чем на мастере.

- **Когда использовать:** Большинство веб-приложений (соцсети, блоги), где чтений в разы больше, чем записей.
- **Примеры:** PostgreSQL, MySQL (стандартная настройка).

---

### **2. Master-Master (Multi-Leader)**

В системе есть несколько равноправных узлов, каждый из которых может принимать и запись, и чтение. Изменения синхронизируются между ними.

- **Преимущества:**
- Высокая доступность: если один мастер упадет, запись продолжается на другой.
- Близость к пользователю: можно поставить один мастер в Европе, другой в США для снижения задержки.

- **Недостатки:**
- **Конфликты записи:** два пользователя могут одновременно изменить одну строку на разных мастерах. Нужно сложное решение конфликтов.
- Сложность настройки и поддержки целостности.

- **Когда использовать:** Географически распределенные системы, где критична доступность на запись.
- **Примеры:** Oracle GoldenGate, сложные кластеры MySQL.

---

### **3. Leaderless (Master-less)**

Концепция «без лидера». Клиент отправляет запрос на запись сразу нескольким узлам (или координатору), и запрос считается успешным, если его подтвердило большинство (кворум).

- **Преимущества:**
- Максимальная отказоустойчивость: система продолжает работать, даже если упадет значительная часть узлов.
- Нет единой точки отказа.

- **Недостатки:**
- Чтение может вернуть старые данные (нужно читать с нескольких узлов для проверки актуальности).
- Очень сложная логика обеспечения согласованности.

- **Когда использовать:** Системы с огромной нагрузкой, где нельзя прерывать работу ни на секунду.
- **Примеры:** Cassandra, DynamoDB, Riak.

---

### **Сводная таблица:**

| Тип               | Запись              | Конфликты        | Сложность     |
| ----------------- | ------------------- | ---------------- | ------------- |
| **Master-Slave**  | Только на 1 узел    | Отсутствуют      | Низкая        |
| **Master-Master** | На любой из лидеров | **Высокие**      | Высокая       |
| **Leaderless**    | На все узлы сразу   | Обработка версий | Очень высокая |

</details>

---

<details>
<summary><span>50. Отказоустойчивость: <b>Failover, Hot Standby, Split Brain</b></span></summary>
<br />

### **1. Failover (Аварийное переключение)**

Это автоматический (или ручной) процесс перевода нагрузки с основного сервера на резервный при обнаружении сбоя.

- **Как это работает:** Система мониторинга понимает, что Master перестал отвечать. Она выбирает наиболее актуальную реплику (Slave) и назначает её новым мастером. Весь трафик приложения перенаправляется на этот новый адрес.
- **Цель:** Минимизировать время простоя (Downtime).

---

### **2. Hot Standby (Горячий резерв)**

Это режим работы резервного сервера, при котором он находится в максимально «разогретом» состоянии.

- **Суть:** Резервный сервер не просто хранит копию данных, а постоянно принимает поток изменений от основного сервера и сразу применяет их.
- **Особенности:**
- База данных на Standby запущена.
- Она готова принять нагрузку практически мгновенно (секунды).
- Часто на Hot Standby разрешены запросы только на чтение (`ReadOnly`).

- **Другие виды:** _Warm Standby_ (база запущена, но не сразу готова к работе) и _Cold Standby_ (база выключена, нужно время на запуск).

---

### **3. Split Brain («Разделение мозга»)**

Это опасная ситуация в кластере, когда из-за сетевого сбоя узлы теряют связь друг с другом, и в системе появляется **два мастера одновременно**.

- **Проблема:** Каждая часть кластера «думает», что другая часть упала, и выбирает своего мастера. Пользователи начинают писать данные на оба сервера.
- **Последствия:** Данные на узлах начинают расходиться (дивергенция). Склеить их потом без потерь практически невозможно.
- **Как лечат:** \* **Quorum (Кворум):** Решение принимается большинством голосов (нужно минимум 3 узла).
- **STONITH (Shoot The Other Node In The Head):** Жесткий механизм, когда один узел физически отключает питание другому через управляемую розетку, чтобы исключить конкуренцию.

---

### **Резюме:**

| Термин          | Роль                                                                |
| --------------- | ------------------------------------------------------------------- |
| **Failover**    | Сам процесс спасения системы при падении лидера.                    |
| **Hot Standby** | Идеальный кандидат на замену, который всегда наготове.              |
| **Split Brain** | Главный кошмар админа — когда в системе два лидера и каша в данных. |

</details>

---

<details>
<summary><span>51. <b>Конфликты репликации</b> и формулы кворума (W, R, N)</span></summary>
<br />

В распределенных системах, где запись может происходить параллельно на разные узлы (Master-Master или Leaderless), неизбежно возникают конфликты данных. Для их решения используются специальные алгоритмы и математические модели.

### **1. Способы решения конфликтов**

Когда два узла получили разные значения для одного и того же ключа, база должна решить, какое из них оставить:

- **LWW (Last Write Wins — Побеждает последняя запись):** Система сравнивает временные метки (timestamp) и оставляет ту запись, которая была сделана позже. Это самый простой, но опасный метод, так как из-за рассинхронизации часов на серверах можно потерять важные данные.
- **Ранг реплик (Replica Priority):** Каждому узлу присваивается приоритет. При конфликте выбираются данные с узла с более высоким рангом.
- **Решение на стороне клиента:** База данных сохраняет все версии конфликтных данных и при чтении отдает их приложению. Разработчик сам пишет логику, как их объединить (как это сделано, например, в корзине Amazon).
- **CRDT (Conflict-free Replicated Data Types):** Специальные структуры данных, которые спроектированы так, что при слиянии из любых узлов они всегда приходят к одному результату автоматически, без конфликтов.

---

### **2. Какие типы данных не подвержены конфликтам?**

Это те самые **CRDT**. Они позволяют обновлять данные независимо и одновременно на разных узлах.

- **Счетчики (Counters):** Например, количество лайков. Неважно, в каком порядке прибавлять "+1", итоговая сумма будет одинаковой.
- **Множества (Sets):** Добавление уникальных элементов.
- **Регистры:** Хранят значения с учетом метаданных для автоматического слияния.

---

### **3. Формула Кворума (W + R > N)**

Для обеспечения согласованности в системах без лидера (Leaderless) используются параметры кворума:

- **N** — общее количество узлов, хранящих копию данных.
- **W** — сколько узлов должны подтвердить **запись**, чтобы она считалась успешной.
- **R** — сколько узлов нужно опросить при **чтении**.

**Основные сценарии:**

1. **$W + R > N$:** Гарантируется **строгая согласованность**. Области записи и чтения пересекаются хотя бы на одном узле, поэтому вы всегда прочитаете свежие данные.
2. **$W + R \leq N$:** Строгая согласованность **не гарантируется**. Возможна ситуация «грязного чтения» старых данных.
3. **$R = 1, W = N$:** Система оптимизирована для **быстрого чтения** (читаем с любого узла), но запись будет медленной и хрупкой (нужны все узлы).
4. **$W = 1, R = N$:** Система оптимизирована для **быстрой записи**, но чтение требует опроса всей сети.

</details>

---

<details>
<summary><span>52. Типы репликации: <b>Sync, Async, Semisync, Loss-less</b></span></summary>
<br />

### **1. Strong Consistency (Синхронная репликация)**

Мастер записывает данные и ждет подтверждения от реплики, прежде чем ответить пользователю «Успешно».

- **Плюсы:** Гарантирует строгую согласованность. Если мастер упадет, на реплике точно будут все данные.
- **Минусы:** Самая низкая скорость. Если реплика «залагает» или пропадет сеть, встанет и запись на мастере.
- **Когда использовать:** В критически важных финансовых системах.

---

### **2. Eventual Consistency (Асинхронная репликация)**

Мастер записывает данные у себя, сразу отвечает пользователю и только потом, в фоновом режиме, отправляет данные на реплики.

- **Replication Lag:** Время, за которое изменения долетают до реплики. Если прочитать данные из реплики сразу после записи, можно увидеть старое значение.
- **Плюсы:** Максимальная скорость записи. Мастер не зависит от состояния реплик.
- **Минусы:** Риск потери данных. Если мастер сгорит до того, как успеет отправить лог на реплику, эти данные пропадут навсегда.
- **Когда использовать:** Соцсети, аналитика, большинство веб-проектов.

---

### **3. Полусинхронная репликация (Semisync)**

Компромиссный вариант. Мастер ждет подтверждения хотя бы от **одной** реплики, что она получила данные (записала в свой Relay Log), но не ждет завершения самой записи в базу.

- **Суть:** Мы уверены, что данные покинули мастер и физически находятся еще где-то в сети.
- **Плюсы:** Быстрее полной синхронизации, но гораздо надежнее асинхронной.

---

### **4. Loss-less Semi-sync (Безаварийная полусинхронная)**

Улучшенная версия полусинхронной репликации.

- **В обычном Semisync:** Сначала `Commit` на мастере, потом ожидание реплики. Если реплика не ответила, а мастер упал, другие пользователи могли успеть увидеть данные, которые в итоге пропадут.
- **В Loss-less:** Мастер сначала ждет подтверждения от реплики и **только потом** делает `Commit` у себя.
- **Результат:** Исключена ситуация, когда данные видны на мастере, но отсутствуют на репликах после аварии.

---

### **Сводная таблица:**

| Тип             | Скорость | Надежность данных | Согласованность             |
| --------------- | -------- | ----------------- | --------------------------- |
| **Синхронная**  | Низкая   | Максимальная      | Строгая (Strong)            |
| **Асинхронная** | Высокая  | Низкая            | В конечном счете (Eventual) |
| **Semisync**    | Средняя  | Высокая           | Компромиссная               |
| **Loss-less**   | Средняя  | Очень высокая     | Повышенная                  |

</details>

---

<details>
<summary><span>53. Тонкие ошибки согласованности (аномалии репликации)</span></summary>
<br />

Когда данные передаются от мастера к фолловерам с задержкой (replication lag), пользователи могут сталкиваться с логическими парадоксами. Вот три классических примера и способы их решения:

### **1. Чтение собственных записей (Read-Your-Writes Consistency)**

**Проблема:** Пользователь отправляет данные (например, комментарий), страница обновляется, но пользователь его не видит, так как запрос на чтение ушел на фолловер, куда данные еще не «долетели». Это выглядит как потеря данных.

**Решение:** \* Отслеживать время последнего обновления пользователя.

- Если обновление было недавно (например, в течение последней минуты), направлять запросы на чтение на **главный узел (Master)**.

### **2. Монотонное чтение (Monotonic Reads)**

**Проблема:** Пользователь читает данные и видит их, но при обновлении страницы они исчезают.

- Это происходит, когда первый запрос попал на «свежий» фолловер, а второй — на тот, что сильнее отстает от мастера. Создается ощущение, что время в системе пошло вспять.

**Решение:** Привязать пользователя к конкретному фолловеру (например, по ID или хэшу сессии), чтобы он всегда читал из одного и того же узла.

### **3. Согласованное префиксное чтение (Consistent Prefix Reads)**

**Проблема (Пример с Twitter):** Нарушение причинно-следственной связи.

- Пользователь А публикует фото собаки.
- Пользователь Б отвечает комплиментом.
- Из-за задержек в разных партициях или узлах третий пользователь может сначала увидеть ответ пользователя Б («Какая милая собака!»), но не видеть само фото пользователя А. В итоге ответ не имеет смысла.

**Решение:** Обеспечить, чтобы любые данные, имеющие причинную связь, записывались и читались из одной и той же партиции или в строгом хронологическом порядке.

---

### **Итоговая таблица аномалий:**

| Аномалия              | Суть проблемы                           | Как лечить?                             |
| --------------------- | --------------------------------------- | --------------------------------------- |
| **Read-Your-Writes**  | «Я только что это записал, но не вижу». | Читать «свои» данные с Мастера.         |
| **Monotonic Reads**   | «Только что было, а теперь пропало».    | Sticky Sessions (привязка к узлу).      |
| **Consistent Prefix** | «Ответ есть, а вопроса еще нет».        | Соблюдение причинно-следственной связи. |

</details>

---

<details>
<summary><span>54. Технологии репликации: <b>Форматы, Способы и Логика</b></span></summary>
<br />

### **1. Источник и модель передачи**

Существует два основных подхода к тому, как реплика узнает об изменениях:

- **Push-модель (напр. PostgreSQL):** Мастер сам «выталкивает» изменения в сторону реплик, как только они происходят. Это минимизирует задержку (lag).
- **Pull-модель (напр. MySQL):** Реплика периодически опрашивает мастер: «Есть ли у тебя новые записи в бинарном логе?». Если есть — забирает их.

---

### **2. Форматы передачи данных (Binlog Formats)**

В зависимости от того, что именно записывается в лог и передается по сети, выделяют три типа:

| Формат                    | Суть (Что передается)                                                                        | Плюсы                                                               | Минусы                                                                                                                                   |
| ------------------------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **Statement-based (SBR)** | Передается сам **SQL-запрос** (например, `UPDATE users SET status='active' WHERE age > 18`). | Очень компактно, создается мало данных в логах.                     | Проблемы с **недетерминированными функциями** (`NOW()`, `RAND()`). На мастере и реплике они вернут разные значения, и данные разойдутся. |
| **Row-based (RBR)**       | Передаются конкретные **изменившиеся строки** (было значение "А", стало "Б").                | Самый надежный способ. Гарантирует **идентичность данных на 100%**. | Если один запрос обновил миллион строк, в лог попадет миллион записей. Это создает **огромную нагрузку на сеть и диск**.                 |
| **Mixed-based**           | **Автоматический режим**: база сама выбирает между SBR и RBR.                                | Оптимальный баланс производительности и надежности.                 | База использует _Statement_, но если видит опасную функцию (вроде `UUID()`), переключается на _Row_.                                     |

---

### **3. Физическая vs Логическая репликация**

| Тип            | Как работает                               | Особенности                                                                                                                |
| -------------- | ------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------- |
| **Физическая** | Копирует данные побайтово (блоки диска).   | Очень быстрая. Нельзя реплицировать между разными версиями БД или только одну таблицу.                                     |
| **Логическая** | Передает поток изменений объектов (строк). | Гибкая. Позволяет передавать данные между разными версиями БД (например, с Pg 12 на Pg 15) или изменять структуру на лету. |

---

### **4. Фильтрация репликации**

Иногда нам не нужно копировать всю базу целиком (например, для аналитики нужны только заказы, а логи не нужны).

- **На стороне мастера:** Можно указать, какие базы или таблицы НЕ должны попадать в бинарный лог.
- **На стороне реплики:** Реплика скачивает всё, но применяет только те изменения, которые соответствуют фильтру (например, `replicate-do-table`).

> **Зачем это:** Экономия диска на репликах и возможность создания специализированных узлов (отдельно для склада, отдельно для пользователей).

</details>

---

<details>
<summary><span>55. Теорема CAP: <b>Consistency, Availability, Partition Tolerance</b></span></summary>
<br />

Теорема CAP — это фундаментальный принцип распределенных систем, который утверждает, что в любой момент времени база данных может обеспечить только два из трех свойств.

### **Три столпа CAP**

1. **Consistency (Согласованность):**
   После успешной записи на любой узел, чтение с любого другого узла вернет эти же обновленные данные. Все пользователи видят одну и ту же версию данных одновременно.
2. **Availability (Доступность):**
   Каждый запрос к работающему узлу системы завершается успешным ответом (без ошибки), даже если некоторые узлы в кластере вышли из строя.
3. **Partition Tolerance (Устойчивость к разделению):**
   Система продолжает работать, даже если связь между узлами потеряна (сетевое разделение). **В распределенных системах это свойство является обязательным.**

---

### **Суть выбора: Почему нельзя всё сразу?**

Поскольку в реальных сетях сбои неизбежны, свойство **P (Устойчивость)** должно быть всегда. Таким образом, выбор сводится к двум вариантам при возникновении сетевого сбоя:

- **CP (Consistency + Partition Tolerance):**
  Если связь между узлами пропала, система **отказывается отвечать** на запросы, чтобы не выдать устаревшие данные. Мы жертвуем доступностью ради точности.
- _Примеры:_ **MongoDB, Redis, etcd.**

- **AP (Availability + Partition Tolerance):**
  Если связь пропала, узлы продолжают отвечать пользователям тем, что у них есть. Данные на узлах могут разойтись. Мы жертвуем точностью ради того, чтобы система «жила».
- _Примеры:_ **Cassandra, CouchDB, DynamoDB.**

> **Важное уточнение (CA):** Системы **CA** возможны только в идеальной среде, где сеть никогда не падает (например, база на одном сервере). В распределенных системах **CA не существует**.

---

### **Сравнение стратегий**

| Тип    | Что важнее? | Что происходит при сбое сети? | Типичное применение                 |
| ------ | ----------- | ----------------------------- | ----------------------------------- |
| **CP** | Точность    | Ошибка (Timeout)              | Банковские транзакции, конфиги.     |
| **AP** | Работа      | Отдает старые данные          | Соцсети, счетчики, корзина товаров. |

</details>

---

<details>
<summary><span>56. <b>Партиционирование</b>: Вертикальное и Горизонтальное</span></summary>
<br />

Партиционирование — это метод оптимизации базы данных, при котором одна большая таблица физически разделяется на несколько более мелких частей (партиций), но при этом логически остается единым целым для пользователя и приложения.

### **Зачем нужно партиционирование?**

1. **Повышение производительности:** Поиск в маленькой части данных (например, только за текущий месяц) происходит намного быстрее, чем во всей таблице за 10 лет.
2. **Упрощение обслуживания:** Можно быстро удалить старые данные, просто удалив одну партицию (DROP PARTITION), вместо тяжелого `DELETE`.
3. **Эффективное управление диском:** Разные части таблицы можно хранить на разных дисках (например, свежие данные на быстрых SSD, а архив — на медленных HDD).

---

### **Виды партиционирования**

#### **1. Вертикальное партиционирование**

Это разделение таблицы по **столбцам**.

- **Суть:** Столбцы таблицы распределяются по разным физическим хранилищам. Часто таблицу делят на «часто используемые» данные и «редко используемые» (например, огромные текстовые поля `blob` или `text`).
- **Пример:** В таблице `Users` мы выносим `id` и `email` в одну таблицу, а `biography` и `avatar_blob` — в другую.
- **Когда использовать:** Когда в таблице слишком много столбцов, но в 90% случаев вы запрашиваете только два-три из них.

#### **2. Горизонтальное партиционирование**

Это разделение таблицы по **строкам**.

- **Суть:** Все столбцы остаются прежними, но строки распределяются по разным частям на основе определенного правила (ключа партиционирования).
- **Пример:** Таблица `Orders` делится на партиции по годам: `orders_2023`, `orders_2024`, `orders_2025`.
- **Когда использовать:** Когда таблица содержит миллионы/миллиарды строк и поиск по ней становится слишком медленным.

---

### **Сравнение подходов**

| Характеристика | Вертикальное                    | Горизонтальное                        |
| -------------- | ------------------------------- | ------------------------------------- |
| **Что делим?** | Столбцы (свойства объекта).     | Строки (экземпляры объектов).         |
| **Результат**  | Таблицы с разным набором полей. | Таблицы с одинаковым набором полей.   |
| **Цель**       | Уменьшить ширину строки (I/O).  | Уменьшить количество строк в индексе. |

</details>

---

<details>
<summary><span>57. <b>Шардирование</b>: Масштабирование Stateful-сервисов</span></summary>
<br />

### **Что такое шардирование и зачем оно нужно?**

**Шардирование** — это стратегия архитектуры базы данных, при которой данные разбиваются на части (шарды) и распределяются по **разным физическим серверам** (узлам).

- **Масштабирование Stateful-сервисов:** В отличие от Stateless-сервисов (которых можно наплодить сколько угодно), базы данных хранят состояние (State). Шардирование — это основной способ **горизонтального масштабирования** таких систем.
- **Зачем:** Чтобы распределить нагрузку на CPU, RAM и диск между несколькими машинами, преодолевая лимиты одного мощного сервера (Vertical Scaling).

---

### **Способы шардирования**

#### **1. Range-based (На основе диапазонов)**

Данные распределяются по шардам в зависимости от диапазона значений определенного ключа (например, ID или дата).

- **Пример:** Шард №1 хранит пользователей с ID от 1 до 100 000, Шард №2 — от 100 001 до 200 000.
- **Плюсы:** Легко реализовать, удобно делать запросы по диапазонам (Range queries).
- **Минусы:** Риск «горячих точек» (Hotspots). Если все новые пользователи активны, нагрузка пойдет только на последний шард.

#### **2. Key-based / Hash-based (На основе хэша)**

К ключу шардирования применяется хэш-функция, результат которой определяет номер сервера.

- **Пример:** `hash(user_id) % количество_шардов`.
- **Плюсы:** Равномерное распределение данных и нагрузки по всем серверам.
- **Минусы:** Сложно добавлять новые сервера. При изменении общего количества шардов (N) хэш-функция начнет указывать на другие сервера, что потребует полной перебалансировки данных (решается через _Consistent Hashing_).

#### **3. Directory-based (На основе справочника)**

Существует отдельный сервис или таблица-маршрутизатор (Lookup table), где указано, какой ключ на каком шарде лежит.

- **Пример:** Запрос идет в «Directory Service», тот говорит: «Данные пользователя Иван лежат на сервере Б».
- **Плюсы:** Максимальная гибкость. Можно перемещать данные между шардами вручную, не меняя алгоритм.
- **Минусы:** Сервис справочника становится единой точкой отказа и «узким местом» по производительности.

---

### **Сравнение способов**

| Метод          | Равномерность     | Запросы по диапазону  | Сложность масштабирования |
| -------------- | ----------------- | --------------------- | ------------------------- |
| **Range**      | Плохая (Hotspots) | Отличная              | Средняя                   |
| **Key (Hash)** | Отличная          | Плохая                | Высокая (без хэширования) |
| **Directory**  | Настраиваемая     | Зависит от реализации | Низкая (гибко)            |

</details>

---

<details>
<summary><span>58. Маршрутизация в шардированных системах: <b>Client, Proxy, Coordinator</b></span></summary>
<br />

Существует три основных архитектурных подхода к тому, где именно будет приниматься решение о выборе нужного шарда.

### **1. Клиентская маршрутизация (Client-side Routing)**

Логика выбора шарда находится непосредственно внутри клиентской библиотеки или приложения.

- **Как работает:** Приложение знает об общем количестве шардов и алгоритме (например, хэш-функции). Оно само вычисляет, на какой сервер пойти, и устанавливает прямое соединение.
- **Плюсы:** Нет лишних сетевых прыжков (hops), минимальная задержка.
- **Минусы:** Сложность обновления. Если вы добавите новый сервер, вам придется обновлять конфиги или код во всех копиях вашего приложения.
- **Пример:** Клиентские библиотеки для **Redis** или **Kafka**.

---

### **2. Прокси-маршрутизация (Proxy-based)**

Между приложением и базой данных стоит промежуточный слой (Load Balancer / Proxy), который берет на себя всю логику.

- **Как работает:** Приложение отправляет запрос на единый адрес прокси-сервера. Прокси анализирует запрос (например, ID пользователя) и перенаправляет его на нужный шард.
- **Плюсы:** Приложение ничего не знает о структуре кластера. Легко добавлять/удалять сервера, меняя настройки только в прокси.
- **Минусы:** Прокси — это лишнее звено, которое вносит небольшую задержку и может стать «узким местом» или точкой отказа.
- **Пример:** **Vitess** (для MySQL), **PgBouncer** (с логикой маршрутизации).

---

### **3. Координатор (Broker / Coordinator)**

Запрос попадает на любой случайный узел кластера, и этот узел сам решает, что делать дальше.

- **Как работает:** Каждый узел кластера знает топологию всей системы. Если вы прислали запрос не на тот сервер, узел-координатор сам перешлет запрос нужному соседу или скажет клиенту, куда обратиться.
- **Плюсы:** Удобство для клиента (можно стучаться в любой IP). Высокая отказоустойчивость.
- **Минусы:** Внутренний трафик между узлами кластера может сильно нагружать сеть.
- **Пример:** **Cassandra**, **Elasticsearch**, **ClickHouse**.

---

### **Сравнение способов маршрутизации**

| Характеристика            | Клиентская        | Прокси (Proxy)       | Координатор                 |
| ------------------------- | ----------------- | -------------------- | --------------------------- |
| **Где логика?**           | В коде приложения | В отдельном сервисе  | Внутри самой БД             |
| **Сложность клиента**     | Высокая           | Низкая (простой SQL) | Средняя                     |
| **Лишний сетевой прыжок** | Нет               | Да                   | Да (иногда внутри кластера) |
| **Гибкость**              | Низкая            | Высокая              | Высокая                     |

</details>

---

<details>
<summary><span>59. <b>Перебалансировка</b> и концепция <b>Virtual Buckets</b></span></summary>
<br />

Перебалансировка (Rebalancing) — это процесс перераспределения данных между узлами в шардированном кластере. Она необходима, когда в систему добавляются новые серверы или когда существующие узлы переполняются.

### **1. Проблема простой перебалансировки**

Если вы используете простое хэширование (например, `hash(key) % N`, где N — количество серверов), то при добавлении хотя бы одного нового сервера значение остатка от деления изменится почти для всех ключей.

- **Результат:** Придется переместить почти **все** данные с одного сервера на другой. Это создаст огромную нагрузку на сеть и надолго «положит» базу.

---

### **2. Решение: Virtual Buckets (Виртуальные бакеты / Секции)**

Чтобы избежать массового перемещения данных, современные базы данных (например, Redis Cluster, Couchbase, Cassandra) используют слой абстракции — **виртуальные бакеты**.

**Как это работает:**

1. **Фиксированное количество бакетов:** Вместо того чтобы привязывать ключ сразу к серверу, система делит всё адресное пространство на фиксированное (и большое) количество логических корзин — бакетов (например, ровно 16384 бакета).
2. **Маппинг Ключ -> Бакет:** Каждый ключ жестко привязан к своему бакету через хэш-функцию: `hash(key) % 16384`. Эта связь никогда не меняется.
3. **Маппинг Бакет -> Сервер:** Серверы владеют наборами этих бакетов. Например:

- Сервер А: бакеты 0–5000
- Сервер Б: бакеты 5001–10000
- Сервер В: бакеты 10001–16383

[Image showing Key -> Virtual Bucket -> Physical Server mapping]

---

### **3. Процесс перебалансировки с бакетами**

Когда вы добавляете новый **Сервер Г**:

- Система просто забирает часть бакетов у серверов А, Б и В и передает их серверу Г.
- Перемещаются только данные, принадлежащие этим конкретным бакетам.
- Остальные 75% данных остаются на своих местах и не участвуют в перемещении.

---

### **Преимущества Virtual Buckets:**

- **Минимальный объем перемещений:** Переносится ровно столько данных, сколько должен хранить новый узел.
- **Простота управления:** Базе данных проще оперировать крупными логическими блоками (бакетами), чем миллиардами отдельных ключей.
- **Гибкость:** Можно дать мощному серверу больше бакетов, а слабому — меньше.

| Характеристика      | Обычный Hash (`% N`)                | Virtual Buckets                                    |
| ------------------- | ----------------------------------- | -------------------------------------------------- |
| **Добавление узла** | Нужно переместить почти все данные. | Перемещается только малая часть данных.            |
| **Сложность**       | Низкая.                             | Требуется таблица маршрутизации (бакет -> сервер). |
| **Равномерность**   | Хорошая.                            | Отличная (можно балансировать весами).             |

</details>

---

<details>
<summary><span>60. Решардинг, Consistent Hashing и Rendezvous Hashing</span></summary>
<br />

### **1. Решардинг (Resharding)**

**Решардинг** — это процесс изменения архитектуры шардирования: изменения ключа шардирования, разделения одного переполненного шарда на два или глобального перераспределения данных.

#### **Отличие от перебалансировки:**

- **Перебалансировка (Rebalancing):** Это «косметический» процесс. Мы просто переносим существующие блоки данных (бакеты) между узлами, не меняя логику того, как данные закреплены за этими блоками.
- **Решардинг (Resharding):** Это «хирургическая операция». Мы меняем саму структуру. Например, у нас был `Range-based` по годам, а мы решили перейти на `Hash-based` по `user_id`. Это требует полной перетряски всех данных в кластере.

#### **Проблемы решардинга:**

1. **Нагрузка (Performance Hit):** Перенос терабайт данных забивает сетевой канал и нагружает диски, замедляя основные запросы пользователей.
2. **Согласованность (Consistency):** Трудно обеспечить доступность на запись в момент, когда данные «переезжают» с одного сервера на другой.
3. **Сложность отката:** Если в процессе решардинга что-то пошло не так, вернуть всё в исходное состояние крайне сложно.

---

### **2. Consistent Hashing (Консистентное хеширование)**

Алгоритм, позволяющий минимизировать объем перемещаемых данных при изменении количества узлов.

- **Принцип:** Все возможные значения хэша представляются в виде кольца (от 0 до ). На это кольцо наносятся и серверы, и данные. Объект принадлежит тому серверу, который встречается первым при движении по часовой стрелке.
- **Проблема — Каскадный сбой:** Если один узел вылетает, вся его нагрузка мгновенно переходит на **один** следующий узел по кольцу. Тот не выдерживает двойной нагрузки и тоже падает, запуская цепную реакцию.
- **Решение — Виртуальные шарды (Vnodes):** Каждый физический сервер представляется на кольце сотнями «виртуальных» точек. Теперь, если сервер падает, его данные (и нагрузка) распределяются **равномерно по всем** остальным узлам кластера, а не падают на одного соседа.

---

### **3. Rendezvous Hashing (Highest Random Weight)**

Альтернатива консистентному хешированию, используемая в системах вроде _Google Maglev_.

- **Принцип:** Для каждого ключа и каждого сервера вычисляется вес: `weight = hash(key + server_id)`. Ключ отправляется на тот сервер, который выдал **максимальный** вес.
- **Плюсы перед Consistent Hashing:**

1. **Не нужно кольцо:** Не нужно хранить и обновлять сложную структуру «кольца» и виртуальных узлов.
2. **Идеальное распределение:** При добавлении или удалении сервера перемещается только необходимый минимум данных (`1/N`), и нагрузка распределяется идеально ровно сразу.
3. **Легко учитывать веса:** Если один сервер мощнее другого, можно просто умножать его хэш-результат на коэффициент.

---

### **Сравнение алгоритмов:**

| Характеристика       | Consistent Hashing                     | Rendezvous Hashing                   |
| -------------------- | -------------------------------------- | ------------------------------------ |
| **Структура**        | Кольцо хэшей                           | Сравнение весов (HRW)                |
| **Сложность поиска** | (бинарный поиск по кольцу)             | (нужно проверить каждый сервер)      |
| **При падении узла** | Нагрузка идет на соседа (нужны vnodes) | Нагрузка сразу делится между всеми   |
| **Применение**       | Cassandra, Memcached, Akamai           | Load balancers (Maglev), кэширование |

</details>

---

<details>
<summary><span>61. <b>CDC (Change Data Capture)</b>: Kafka Connect и Libslave</span></summary>
<br />

Да, эти технологии работают в одной связке для решения задачи: «Как мгновенно узнать, что в базе что-то изменилось, и передать это в другие системы?».

### **1. CDC (Change Data Capture)**

Это концепция (подход). Вместо того чтобы периодически опрашивать базу запросом `SELECT * FROM table WHERE updated_at > ...` (что тяжело и медленно), CDC слушает **логи изменений** самой базы (Binlog в MySQL или WAL в Postgres).

- **Зачем:** Чтобы обновлять кэши, поисковые индексы (Elasticsearch) или переливать данные в аналитическое хранилище в реальном времени.

---

### **2. Libslave**

Это низкоуровневая библиотека (часто используемая в экосистеме MySQL).

- **Суть:** Она притворяется «фейковой репликой» (slave). Она подключается к мастеру, представляется как обычный Slave-сервер и начинает получать поток Binlog-событий.
- **Роль:** Это «щуп», который вытаскивает сырые данные из бинарного лога базы данных. Она парсит записи (например, формат Row-based) и превращает их в понятные программные события (Insert/Update/Delete).

---

### **3. Kafka Cluster и CDC**

**Apache Kafka** выступает в роли «транспортной магистрали» и хранилища для этих изменений.

- **Как это работает в связке:**

1. **Connector (на базе Libslave или Debezium):** Читает Binlog базы.
2. **Producer:** Отправляет каждое изменение как отдельное сообщение в Kafka-топик.
3. **Kafka Cluster:** Надежно хранит эти сообщения.
4. **Consumers:** Любые другие сервисы подписываются на топик и мгновенно узнают, что в базе обновилась строка.

---

### **Сводная таблица ролей:**

| Компонент         | Роль в процессе                         | Аналогия                               |
| ----------------- | --------------------------------------- | -------------------------------------- |
| **База данных**   | Источник первичных данных.              | Автор газеты.                          |
| **Libslave**      | Библиотека для чтения логов базы.       | Читатель, который переписывает статью. |
| **CDC (Процесс)** | Технология отслеживания изменений.      | Система доставки новостей.             |
| **Kafka Cluster** | Шина данных для доставки этих новостей. | Газетный киоск/почта.                  |

---

### **Почему это круто?**

- **Минимальная нагрузка на Master:** Чтение лога гораздо легче, чем выполнение тяжелых SQL-запросов.
- **Real-time:** Задержка между записью в БД и появлением данных в Kafka обычно составляет миллисекунды.
- **Decoupling:** Базе данных не нужно знать, кто потребляет её данные. Она просто пишет логи, а Kafka раздает их всем желающим.

</details>

---

<details>
<summary><span>62. Стратегии развертывания: <b>Rolling, Blue/Green, Canary</b></span></summary>
<br />

Эти термины описывают стратегии развертывания (Deployment Strategies) — способы обновления приложения, которые позволяют минимизировать или полностью исключить простой системы (Downtime) и риск поломки для всех пользователей сразу.

### **1. Rolling Release (Постепенное обновление)**

Самый распространенный метод в Kubernetes. Новая версия приложения устанавливается на сервера по очереди.

- **Как работает:** Система выключает один узел (или группу) старой версии (**V1**), заменяет его новой (**V2**) и переходит к следующему только после того, как новый узел успешно прошел проверку здоровья (Health Check).
- **Плюсы:** Не требует удвоения ресурсов сервера.
- **Минусы:** В процессе обновления в кластере одновременно работают и старая, и новая версии (проблема совместимости данных).
- **Риск:** Если в **V2** есть критический баг, он успеет затронуть часть пользователей до того, как деплой будет остановлен.

---

### **2. Blue/Green Release (Сине-зеленое развертывание)**

Метод, обеспечивающий мгновенное переключение между версиями.

- **Как работает:** Параллельно работают две идентичные среды. **Blue** — текущая (рабочая), **Green** — новая версия. Когда **Green** полностью готова и протестирована, балансировщик трафика одним кликом перенаправляет всех пользователей с Blue на Green.
- **Плюсы:** Нулевой простой. Мгновенный откат (Rollback) — если в Green нашли баг, просто переключаем трафик обратно на Blue.
- **Минусы:** Дороговизна, так как нужно **в 2 раза больше мощностей** (серверов), чтобы держать две копии системы.

---

### **3. Canary Release (Канареечный релиз)**

Название пошло от практики шахтеров брать с собой канарейку: если она замолкала, значит, в шахте газ.

- **Как работает:** Новая версия раскатывается на очень маленькую группу пользователей (например, 5%). Мы мониторим ошибки и метрики этой группы. Если всё хорошо, процент постепенно увеличивается до 100%.
- **Плюсы:** Самый безопасный метод. Если в коде ошибка, пострадает лишь малая часть аудитории. Можно тестировать новые фичи на реальном трафике.
- **Минусы:** Сложная настройка маршрутизации трафика и мониторинга.
- **Пример:** Facebook сначала выкатывает фичу на сотрудников, потом на Новую Зеландию, и только потом на весь мир.

---

### **Сводная таблица сравнения**

| Характеристика         | Rolling               | Blue/Green         | Canary           |
| ---------------------- | --------------------- | ------------------ | ---------------- |
| **Простой (Downtime)** | Нулевой               | Нулевой            | Нулевой          |
| **Стоимость ресурсов** | Низкая (100% + запас) | **Высокая (200%)** | Низкая           |
| **Скорость отката**    | Средняя               | **Мгновенная**     | Быстрая          |
| **Безопасность**       | Средняя               | Высокая            | **Максимальная** |

</details>

---

<details>
<summary><span>63. Где хранить статику и архитектурные схемы (MVP и далее)</span></summary>
<br />

### **1. Где хранить статику? (От простого к сложному)**

| Метод                                                   | Суть                                                                                                                             | Когда использовать                                                                                                                                                             |
| ------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Локально в репозитории (Asset Pipeline):**            | Файлы лежат прямо в папке с кодом проекта.                                                                                       | Только для критичных CSS/JS и иконок. Плохо для картинок пользователей, так как при каждом деплое или масштабировании (новом инстансе) файлы будут теряться или дублироваться. |
| **Выделенное хранилище на сервере (Local Disk / NAS):** | Отдельная папка на диске, которую раздает Nginx.                                                                                 | **MVP** или небольшие внутренние проекты. Дешево, но сложно масштабировать на несколько серверов.                                                                              |
| **Объектное хранилище (S3-like):**                      | Сервисы вроде AWS S3, Google Cloud Storage или MinIO. Файлы хранятся не как в файловой системе, а как объекты с уникальными URL. | **Стандарт для современных систем**. Неограниченный объем, высокая надежность, легко интегрируется.                                                                            |
| **CDNs (Content Delivery Network):**                    | Сеть серверов по всему миру (Cloudflare, Akamai), которая кэширует вашу статику максимально близко к пользователю.               | Когда проект вышел за рамки одной страны или статики очень много.                                                                                                              |

---

### **2. Архитектурные схемы**

#### **А. MVP (Минимально жизнеспособный продукт)**

Обычно это **двухзвенная** архитектура или упрощенная трехзвенная.

1. **Client:** Браузер или мобильное приложение.
2. **Monolith (App + DB):** Один сервер, где крутится и код, и база данных, и там же на диске лежит статика.

- _Плюсы:_ Максимальная скорость разработки, нулевая стоимость инфраструктуры.
- _Минусы:_ Падает сервер — падает всё. Сложно обновлять.

#### **Б. Классическая трехзвенная архитектура (Three-Tier)**

Разделение ответственности на три уровня:

1. **Presentation Tier (Уровень представления):** Веб-сервер (Nginx) или фронтенд-фреймворк. Занимается отображением и раздачей статики.
2. **Logic Tier (Уровень логики):** Бэкенд-сервер (API), где живет бизнес-логика.
3. **Data Tier (Уровень данных):** Отдельный сервер базы данных.

- _Преимущество:_ Можно масштабировать уровни независимо (например, добавить больше API-серверов, не трогая БД).

#### **В. N-звенная архитектура (N-Tier / Микросервисы)**

Современный стандарт для крупных систем.

- **Client** -> **CDN** (для статики) -> **API Gateway** -> **Microservices** -> **Caches (Redis)** -> **DB Clusters**.
- Статика здесь полностью вынесена в S3 + CDN, чтобы не нагружать основные вычислительные серверы.

---

### **Сравнение стратегий для статики**

| Метод                    | Сложность | Масштабируемость | Скорость для юзера |
| ------------------------ | --------- | ---------------- | ------------------ |
| **Внутри папки проекта** | Низкая    | Нулевая          | Зависит от сервера |
| **S3 Хранилище**         | Средняя   | Бесконечная      | Высокая            |
| **S3 + CDN**             | Высокая   | Бесконечная      | **Максимальная**   |

</details>

---

<details>
<summary><span>64. Способы обмена данными: <b>Polling, Streaming, WebSocket, Pub/Sub</b></span></summary>
<br />

Выбор метода зависит от того, насколько критична задержка (latency) и как часто обновляются данные.

### **1. Polling (Опрос)**

- **Short Polling:** Клиент раз в N секунд спрашивает: «Есть новости?». Сервер сразу отвечает «Да» или «Нет».
- _Минус:_ Много лишних пустых запросов.

- **Long Polling:** Клиент спрашивает, но сервер **держит соединение открытым**, пока данные не появятся (или не выйдет таймаут).
- _Когда лучше:_ Когда данные обновляются редко и не нужна мгновенная реакция.

### **2. Streaming vs WebSockets**

- **WebSockets:** Двусторонний (Full-duplex) канал. Идеально для чатов и игр.
- **Streaming (SSE - Server-Sent Events):** Односторонний канал от сервера к клиенту. Легче в реализации, чем сокеты.
- **Сравнение:** **Polling** — это про периодичность (дискретность). **Streaming** — когда периодичности нет, данные льются потоком по мере появления.

### **3. Pub/Sub (Publisher/Subscriber)**

Паттерн для обмена сообщениями между сервисами через брокер (напр. Redis, RabbitMQ).

- Издатель отправляет сообщение в «тему» (topic), не зная, кто его получит.
- Подписчики получают копию сообщения. Это позволяет максимально «развязать» компоненты системы.

---

### **4. Service Discovery**

В динамической среде (Docker, K8s) IP-адреса сервисов постоянно меняются.

- **Service Discovery** — это «телефонная книга» (напр. Consul, Eureka), где каждый сервис регистрирует свой адрес, чтобы другие могли его найти.

</details>

---

<details>
<summary><span>65. Отказоустойчивость: <b>Retries, Backoff, Circuit Breaker, Idempotency</b></span></summary>
<br />

Если сервис Б не отвечает сервису А, мы должны уметь правильно обработать эту ошибку.

### **1. Идемпотентность и Retries**

- **Retry:** Повторный запрос при ошибке.
- **Проблема:** Если запрос на оплату прошел, но ответ потерялся, повторный запрос спишет деньги второй раз.
- **Решение:** **Ключ идемпотентности** (Idempotency Key / Request ID). Клиент генерирует уникальный ID. Сервер проверяет: «Я уже обрабатывал этот ID?». Если да — просто возвращает старый результат без повторного действия.

### **2. Backoff и Backpressure**

- **Exponential Backoff:** Нельзя делать ретраи каждую секунду. Нужно увеличивать паузу: 1с, 2с, 4с, 8с... чтобы не «добить» и без того упавший сервис.
- **Backpressure (Обратное давление):** Когда приемник не успевает обрабатывать данные, он сообщает отправителю: «Замедлись!». Это предотвращает переполнение очередей и падение памяти.

### **3. Circuit Breaker (Предохранитель)**

Защищает систему от лавинообразного падения. Состояния:

1. **Closed (Закрыт):** Всё хорошо, запросы проходят.
2. **Open (Открыт):** Ошибок слишком много. Запросы сразу отбиваются ошибкой, не доходя до сервиса. Даем ему «отдохнуть».
3. **Half-Open (Полуоткрыт):** Пропускаем один пробный запрос. Если он успешен — закрываем предохранитель.

---

### **4. Graceful Degradation и Fallback**

- **Graceful Degradation:** Способность системы работать частично (например, если сервис рекомендаций упал, главная страница покажет просто список популярных товаров, но не упадет целиком).
- **Fallback:** Резервный план. «Если не удалось получить данные из кэша и БД — верни пустой список или данные из статического файла».

</details>

---

<details>
<summary><span>66. Паттерны данных: <b>CQRS, MapReduce, Кэширование</b></span></summary>
<br />

### **1. CQRS (Command Query Responsibility Segregation)**

Разделение модели **Записи** (Command) и модели **Чтения** (Query).

- _Зачем:_ Читать данные часто нужно совсем в другом виде, чем мы их пишем. Можно использовать быструю БД для записи (напр. Postgres) и эластик для поиска (чтения).

### **2. Тегирование и Версионирование кэша**

- **Версионирование:** Добавление версии в ключ (`user_v1_123`). При изменении схемы данных просто меняем версию в коде, и старый кэш игнорируется.
- **Тегирование:** Присвоение тегов записям кэша. Позволяет сбросить (инвалидировать) сразу все записи с тегом `articles`, не трогая остальной кэш.

### **3. MapReduce**

Модель обработки огромных объемов данных на кластере:

1. **Map:** Разделяем задачу на части и раздаем рабочим узлам.
2. **Reduce:** Собираем результаты от всех узлов в один итоговый ответ.

</details>

---

<details>
<summary><span>67. Отложенное выполнение задач</span></summary>
<br />

### **Проблема вариативности нагрузки**

Пример с YouTube: сегодня видео аплоадится за 1 час, а завтра за 3 часа.

- **Причина:** Нагрузка на кластер кодирования видео неравномерна.
- **Решение:** Очереди задач. Мы не заставляем пользователя ждать окончания обработки. Мы говорим: «Принято», кладем задачу в очередь, и рабочие узлы (Workers) разгребают её по мере сил.
- **User Experience:** Если очередь выросла, время обработки увеличивается, но система не падает и продолжает принимать новые файлы.

</details>

---

<details>
<summary><span>68. Взаимодействие в микросервисах: <b>Агрегатор</b> и <b>Цепочка</b></span></summary>
<br />

Когда функционал разбит на множество мелких сервисов, возникает вопрос: как собрать данные для пользователя, если они лежат в разных местах?

### **1. Паттерн «Агрегатор» (Aggregator)**

Это сервис (или API Gateway), который принимает один запрос от клиента, делает параллельные запросы к нескольким микросервисам, объединяет их ответы и отдает клиенту единый результат.

- **Пример:** Страница товара. Агрегатор идет в `Service A` за описанием, в `Service B` за ценой и в `Service C` за остатками на складе.
- **Плюсы:** Клиент делает всего один сетевой запрос. Логика объединения скрыта внутри.
- **Минусы:** Агрегатор может стать «узким местом» (bottleneck) и точкой отказа.

### **2. Паттерн «Цепочка» (Chaining)**

Сервисы вызываются последовательно: Клиент -> Сервис А -> Сервис Б -> Сервис В.

- **Пример:** Оформление заказа. `Order Service` создает заказ, затем вызывает `Payment Service` для оплаты, который в свою очередь вызывает `Inventory Service` для резерва товара.
- **Плюсы:** Прямая и понятная последовательность действий.
- **Минусы:** Длинные цепочки увеличивают время ответа (задержка суммируется). Если хотя бы одно звено в середине упадет, вся цепочка прервется.

</details>

---

<details>
<summary><span>69. Событийно-ориентированная архитектура (EDA): <b>3 типа взаимодействия</b></span></summary>
<br />

Вместо прямых вызовов (REST/gRPC) сервисы общаются через шину сообщений (Kafka/RabbitMQ). Мартин Фаулер выделяет несколько ключевых подходов в EDA:

### **1. Event Notification (Оповещение о событии)**

Сервис отправляет минимальное сообщение: «Произошло событие X с объектом ID=123».

- **Как работает:** Получатель, узнав об изменении, должен сам прийти в сервис-источник по API, чтобы забрать детали.
- **Плюсы:** Сообщения очень легкие. Высокая степень независимости (Decoupling).
- **Минусы:** Повышенная нагрузка на источник, так как все подписчики придут к нему за подробностями.

### **2. Event-Carried State Transfer (Передача состояния в событии)**

Сервис отправляет в сообщении **все данные**, которые изменились.

- **Как работает:** «Пользователь 123 сменил email на new@mail.com. Получателю не нужно никуда идти, он просто обновляет свою локальную копию данных (кэш).
- **Плюсы:** Максимальная автономность. Получатель может работать, даже если сервис-источник недоступен.
- **Минусы:** Дублирование данных по всей системе. Нужно следить за тем, чтобы данные во всех сервисах не «разошлись».

### **3. Event Collaboration (Событийное сотрудничество)**

В этом подходе нет центрального «контроллера» бизнес-процесса. Сервисы просто реагируют на действия друг друга.

- **Пример:** Заказ создан -> Склад увидел событие и зарезервировал товар -> Доставка увидела событие резерва и назначила курьера.
- **Плюсы:** Гибкость — легко добавить нового участника процесса, просто подписав его на события.
- **Минусы:** Очень трудно понять общую логику процесса («кто за чем идет»), просто глядя на код одного сервиса.

### **Итоговое сравнение стратегий EDA:**

| Паттерн            | Что внутри сообщения?     | Зависимость от источника         | Нагрузка на сеть             |
| ------------------ | ------------------------- | -------------------------------- | ---------------------------- |
| **Notification**   | Только ID и тип события.  | **Высокая** (нужен доп. запрос). | Низкая (сообщения мелкие).   |
| **State Transfer** | Полный объект (Snapshot). | **Нулевая**.                     | Высокая (сообщения тяжелые). |
| **Collaboration**  | Команда/Факт действия.    | Зависит от реализации.           | Средняя.                     |

</details>

---

<details>
<summary><span>70. Оптимизация вызовов: <b>Throttling</b> и <b>Debouncing</b></span></summary>
<br />

| Метод                                               | Суть                                                                                                        | Как работает                                                                                                                                                                                                                            | Аналогия                                                                                                                                                                                               | Где использовать                                                                                                                                                                                                                      |
| --------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Throttling (Троттлинг)**                          | Гарантирует, что функция будет вызываться **не чаще одного раза в указанный период времени**.               | Если мы установили лимит в 1 секунду, и пользователь совершает 10 действий, функция выполнится в начале секунды, а все остальные нажатия в течение этой секунды будут проигнорированы. Следующий вызов возможен только через 1 секунду. | Кран с водой, который выдает ровно одну каплю в секунду, как бы сильно вы на него ни давили.                                                                                                           | - Отслеживание прокрутки страницы (`onScroll`) — чтобы не пересчитывать положение элементов 100 раз в секунду.<br>- Изменение размера окна (`onResize`).<br>- Обработка игровых событий (например, стрельба в шутере).                |
| **Debouncing (Дебаунсинг / «Устранение дребезга»)** | Откладывает вызов функции до тех пор, пока не пройдет определенное время **с момента последнего действия**. | Каждый раз, когда происходит событие, «таймер ожидания» сбрасывается. Функция выполнится только тогда, когда пользователь сделает паузу.                                                                                                | Лифт в многоэтажке. Он не едет сразу, как только зашел первый человек. Он ждет 5-10 секунд: если зайдет кто-то еще, таймер обнулится. Лифт поедет только тогда, когда в него перестанут заходить люди. | - Живой поиск (Autocomplete) — чтобы не отправлять запрос на сервер после каждой введеной буквы, а подождать, пока пользователь допишет слово.<br>- Кнопка отправки формы — чтобы предотвратить двойной клик и создание двух заказов. |

---

### **Сравнение Throttling и Debouncing**

| Характеристика       | Throttling                            | Debouncing                         |
| -------------------- | ------------------------------------- | ---------------------------------- |
| **Главная цель**     | Ограничить частоту (постоянный ритм). | Ждать затишья (паузы).             |
| **Когда сработает?** | Регулярно во время процесса.          | Только в конце (после паузы).      |
| **Исполнение**       | Раз в миллисекунд.                    | Через мс после последнего события. |
| **Лучший пример**    | Скролл страницы.                      | Поле ввода поиска.                 |

[Image showing Throttling vs Debouncing timelines comparison]

---

### **Почему это важно для System Design?**

Эти механизмы используются не только на фронтенде, но и на уровне API (Rate Limiting) и в распределенных системах:

1. **Защита ресурсов:** Мы не даем клиенту «заспамить» бэкенд тяжелыми запросами.
2. **Экономия:** Меньше запросов — меньше затрат на трафик, CPU и облачные вычисления.

</details>

---

<details>
<summary><span>71. Распределенные транзакции: <b>2PC, Saga, Outbox/Inbox</b></span></summary>
<br />

В распределенных системах данные разнесены по разным базам, и обеспечить **ACID** становится сложно.

### **1. Двухфазная фиксация (2PC — Two-Phase Commit)**

Это классический протокол для обеспечения атомарности.

- **Фаза 1 (Prepare):** Координатор спрашивает все узлы: «Готовы ли вы записать данные?». Узлы проверяют условия и блокируют ресурсы.
- **Фаза 2 (Commit/Abort):** Если **все** ответили «Да», координатор дает команду на запись. Если хотя бы один ответил «Нет» или промолчал — всем рассылается команда отката.
- **Минус:** Низкая производительность из-за блокировок. Если координатор упадет между фазами, система «зависнет».

### **2. Паттерн Saga**

Вместо блокировок используется цепочка локальных транзакций.

- Для каждого действия есть **компенсирующее действие** (откат).
- Если на шаге №3 произошла ошибка, Сага последовательно выполняет откаты шагов №2 и №1.
- _Виды:_ **Оркестрация** (центр управления) и **Хореография** (сервисы реагируют на события).

### **3. Transactional Outbox / Inbox**

Паттерн для надежной передачи событий между БД и брокером (Kafka).

- **Outbox:** В одной транзакции мы пишем данные в таблицу сущностей и в специальную таблицу `outbox`. Отдельный процесс (Relay) читает таблицу `outbox` и отправляет сообщения в брокер. Это гарантирует, что событие не потеряется, если брокер упал.
- **Inbox:** Аналогично на стороне получателя — сначала сохраняем входящее событие в БД, а потом обрабатываем, чтобы избежать дубликатов при повторных доставках.

</details>

---

<details>
<summary><span>72. Консенсус и координация: <b>Raft, Paxos, Лидеры</b></span></summary>
<br />

Консенсус — это когда несколько узлов должны договориться об одном значении (например, кто сейчас Master).

### **1. Выбор лидера (Leader Election)**

В кластере должен быть главный узел, который координирует запись.

- **Алгоритм забияки (Bully Algorithm):** Когда узел замечает, что лидер упал, он отправляет запрос всем узлам с ID выше своего. Если никто не ответил — он объявляет себя лидером. Если ответили «старшие» — они начинают свои выборы. Побеждает самый «сильный» (с наибольшим ID).

### **2. Raft и Paxos**

Это современные протоколы консенсуса.

- **Paxos:** Первый теоретически верный протокол. Очень сложен в реализации.
- **Raft:** Разработан как более понятная альтернатива Paxos. Использует три состояния: _Follower, Candidate, Leader_. Построен на репликации логов.
- **Где используются:** **etcd** (основа Kubernetes) использует Raft; **Zookeeper** использует ZAB (похож на Paxos).

### **3. Распределенные блокировки (Distributed Locks)**

Нужны, чтобы разные процессы не правили один и тот же ресурс одновременно.

- Обычно реализуются через **Redis (Redlock)** или **Zookeeper/etcd**.
- Важно использовать **TTL** (время жизни), чтобы если владелец блокировки «умрет», ресурс не остался заблокированным навсегда.

</details>

---

<details>
<summary><span>73. Проектирование систем: <b>Функциональные и Нефункциональные требования</b></span></summary>
<br />

Перед тем как рисовать схему в System Design, нужно четко очертить границы задачи.

### **1. Функциональные требования (FR)**

_Что система должна делать?_ Это конкретные фичи.

- _Пример (для YouTube):_ Пользователь может загружать видео. Пользователь может ставить лайки. Система должна поддерживать поиск по названиям.

### **2. Нефункциональные требования (NFR)**

_Как система должна работать?_ Это ограничения и качества.

- **Масштабируемость:** Система должна выдерживать 100 млн пользователей.
- **Доступность (Availability):** 99.9% времени (три девятки).
- **Задержка (Latency):** Видео должно начинать играть не дольше чем через 200 мс.
- **Надежность (Durability):** Загруженное видео не должно потеряться ни при каких обстоятельствах.

> **Зачем это разделять?** FR определяют архитектуру кода (логику), а NFR определяют архитектуру инфраструктуры (шардирование, репликацию, CDN).

</details>

---

<!-- <details>
<summary><span></span></summary>
<br />

</details>

--- -->
