<a href="./README.md">← Назад</a>

<div align="center">
  <img src="../../assets/icons/icons-for-titles/system-design.png">
  <h2>System Design</h2>
</div>
<br />

<details>
<summary><span>1. Какие есть <b>архитектуры ИС</b>?</span></summary>
<br />

1. **Файл-сервер** — простая архитектура, где сервер лишь хранит файлы, а обработка данных идет на ПК пользователя.

   > _Примеры:_ Локальные сети малых офисов с общими папками, старые версии систем «1С:Предприятие 7.7», простые базы данных на базе Microsoft Access.

2. **Клиент-сервер** — разделение на поставщиков (серверы) и заказчиков (клиенты) услуг.

   > _Примеры:_ Современные веб-сайты, банковские системы, онлайн-игры (например, World of Warcraft), корпоративные ERP-системы (SAP, Oracle).

3. **Peer to Peer (P2P)** — децентрализованная сеть, где каждый участник одновременно является и клиентом, и сервером.
   > _Примеры:_ Сеть BitTorrent для обмена файлами, блокчейн-сети (Bitcoin, Ethereum), мессенджеры с прямым шифрованием (некоторые функции Signal или Briar).

</details>

---

<details>
<summary><span>2. Основные <b>критерии систем</b>?</span></summary>
<br />

- **Доступность (Availability)** — доля времени, в течение которого система находится в рабочем состоянии и готова отвечать на запросы пользователей (часто измеряется в «девятках», например, 99.9%).
- **Эффективность** — способность системы выполнять задачи с минимальными затратами ресурсов (процессорного времени, памяти, трафика).
- **Надежность** — способность системы безотказно работать в заданных условиях в течение определенного времени.
- **Масштабируемость** — возможность системы справляться с растущей нагрузкой путем добавления ресурсов без изменения архитектуры.
- **Безопасность** — комплекс мер по защите данных от кражи, искажения или блокировки доступа.
- **Управляемость** — простота мониторинга, настройки и обновления системы в процессе эксплуатации.
- **Производительность (Performance)** — количественная характеристика того, как быстро система выполняет операции и какой объем данных может обработать.

</details>

---

<details>
<summary><span>3. Каким бывает <b>масштабирвание</b>?</span></summary>
<br />

- **Вертикальное масштабирование (Scale-up)** — увеличение производительности системы за счет наращивания мощности одного узла (увеличение объема RAM, количества ядер процессора или скорости дисков).

  > _Пример:_ Покупка более мощного сервера для базы данных.

- **Горизонтальное масштабирование (Scale-out)** — увеличение производительности за счет добавления новых узлов (серверов) в систему, которые работают параллельно.

  > _Пример:_ Добавление десяти обычных серверов в кластер для распределения веб-трафика.

Вертикальное масштабирование проще в реализации, но имеет физический «потолок», в то время как горизонтальное - почти безгранично, но требует более сложной архитектуры ПО.

</details>

---

<details>
<summary><span>4. Что такое <b>SLA / SLO / SLI?</b></span></summary>
<br />

- **SLI (Service Level Indicator)** — это конкретный количественный показатель (метрика), который мы измеряем здесь и сейчас. Это «градусник» системы

  > _Пример:_ Время ответа сервера (latency) или процент успешных запросов (error rate).

- **SLO (Service Level Objective)** — это целевое значение или диапазон значений для выбранного SLI, который мы хотим поддерживать. Это внутренняя цель команды инженеров.

  > _Пример:_ «99,9% запросов должны обрабатываться быстрее чем за 200 мс».

- **SLA (Service Level Agreement)** — это внешнее обязательство (договор) перед клиентом, в котором прописано, что будет, если SLO не будет достигнут.Это юридический документ с финансовыми последствиями (штрафы, возвраты).
  > _Пример:_ «Если доступность сервиса упадет ниже 99%, мы вернем клиентам 10% стоимости подписки».

**Важный нюанс:** Инженеры обычно стараются сделать **SLO чуть строже, чем SLA**. Это создает «запас прочности» (Error Budget), чтобы успеть починить систему до того, как придется платить штрафы клиентам.

</details>

---

<details>
<summary><span>5. Что такое <b>Stateless / Stateful</b>?</span></summary>
<br />

- **Stateless (Без сохранения состояния)** — архитектура, при которой сервер не хранит информацию о предыдущих запросах клиента. Каждый запрос должен содержать абсолютно все данные, необходимые для его обработки.

  > _Пример:_ Поиск в Google. Каждый ваш поисковый запрос автономен. Если вы закроете вкладку и откроете снова, сервер не будет "помнить", что вы искали минуту назад, пока вы не отправите новый запрос.

- **Stateful (С сохранением состояния)** — архитектура, в которой сервер «помнит» контекст взаимодействия с клиентом. Состояние (сессия) хранится на стороне сервера и влияет на обработку последующих запросов.
  > _Пример:_ Старый интернет-магазин с корзиной на сессиях. Вы добавляете товар в корзину на одном сервере, и этот сервер хранит список товаров в своей памяти. Если следующий запрос попадет на другой сервер (без синхронизации), корзина окажется пустой.

---

**Краткое сравнение:**

| Критерий               | Stateless                                              | Stateful                                                |
| ---------------------- | ------------------------------------------------------ | ------------------------------------------------------- |
| **Масштабируемость**   | Высокая (любой сервер обработает любой запрос)         | Сложная (нужна синхронизация данных между серверами)    |
| **Отказоустойчивость** | Высокая (падение сервера не теряет данные клиента)     | Ниже (при падении сервера теряется сессия пользователя) |
| **Передача данных**    | Запросы тяжелее (нужно каждый раз слать токены/данные) | Запросы легче (сервер уже знает, кто вы и что делали)   |

</details>

---

<details>
<summary><span>6. Что такое <b>Latency, Response Time, Throughput?</b></span></summary>
<br />

- **Latency (Задержка)** — это время, которое требуется пакету данных или запросу, чтобы пройти путь от отправителя до получателя. Это чистая «задержка в пути».

  > _Пример:_ Время, за которое электрический сигнал доходит от вашего ПК до игрового сервера.

- **Response Time (Время отклика)** — это полное время, которое пользователь ждет ответа после отправки запроса. Оно включает в себя _Latency_ + время, затраченное сервером на обработку задачи.

  > _Пример:_ Вы нажали «Купить», запрос дошел до сервера (задержка), сервер проверил баланс и списал деньги (обработка), и ответ вернулся вам. Всё это вместе — время отклика.

- **Throughput (Пропускная способность)** — это количество запросов или объем данных, которые система может обработать за определенный промежуток времени.
  > _Пример:_ Веб-сервер, обрабатывающий 5000 запросов в секунду (RPS), или канал связи со скоростью 100 Мбит/с.

---

**Простая аналогия:**
Представьте дорогу.

- **Latency** — это то, как быстро одна машина проезжает от города А до города Б (скорость).
- **Throughput** — это то, сколько машин может проехать по этой дороге за час (количество полос).

Эти метрики тесно связаны: если **Throughput** достигает своего предела, запросы начинают вставать в очередь, что мгновенно увеличивает **Response Time**.

</details>

---

<details>
<summary><span>7. Типы нагрузки: <b>Data-intensive vs Compute-intensive?</b></span></summary>
<br />

- **Data-intensive (Интенсивные по данным)** — системы, где основной сложностью является объем данных, их сложность или скорость их изменения, а не вычисления.

  > _Пример:_ Социальные сети (Facebook, Instagram) или базы данных, где нужно быстро сохранять и искать миллиарды постов.

- **Compute-intensive (Интенсивные по вычислениям)** — системы, где на первый план выходит нагрузка на процессор (CPU). Данных может быть немного, но алгоритмы их обработки очень сложные.
  > _Пример:_ Сервисы видеомонтажа, рендеринг 3D-графики, майнинг криптовалют или обучение нейросетей.

</details>

---

<details>
<summary><span>8. Что такое <b>Read / Write Ratio?</b></span></summary>
<br />

- **Read / Write Ratio (Соотношение чтения и записи)** — показатель, который определяет, какая операция в системе преобладает. От этого зависит выбор архитектуры базы данных и стратегии кэширования.
- **Read-heavy (Тяжелое чтение)** — пользователи читают данные гораздо чаще, чем создают новые.

  > _Пример:_ Новостной портал или Википедия (одну статью пишут один раз, а читают миллионы). Здесь критически важен **кэш**.

- **Write-heavy (Тяжелая запись)** — система получает огромный поток входящих данных, которые нужно успевать записывать.

  > _Пример:_ Системы сбора логов, датчики интернета вещей (IoT) или биржевые котировки. Здесь важна **высокая пропускная способность БД на запись**.

  **Почему это важно для архитектора?**
  Если ты понимаешь, что система **Read-heavy**, ты добавишь **Read-реплики** для базы данных. А если она **Compute-intensive**, ты будешь думать о вертикальном масштабировании CPU или использовании GPU.

</details>

---

<details>
<summary><span>9. Какой бывает <b>архитектура бэкенда?</b></span></summary>
<br />

- **Монолит (Monolith)** — архитектура, в которой все компоненты приложения (логика, работа с БД, интерфейс) собраны в один единый исполняемый файл или проект.

  > _Пример:_ Небольшой интернет-магазин, написанный на Django или Ruby on Rails, где весь код живет в одном репозитории и разворачивается целиком.

- **Микросервисы (Microservices)** — подход, при котором приложение разбивается на набор маленьких, независимых сервисов, каждый из которых отвечает за свою бизнес-функцию и общается с другими по сети (API).

  > _Пример:_ Netflix или Amazon. Один сервис отвечает за авторизацию, другой за рекомендации, третий за оплату. Если "упадет" сервис рекомендаций, пользователи всё равно смогут оплатить подписку.

  **Важный совет:** Обычно рекомендуют начинать с **монолита**, чтобы быстро проверить идею (MVP), и переходить на **микросервисы** только тогда, когда команда и нагрузка вырастут настолько, что монолит станет "тесным".

</details>

---

<details>
<summary><span>10. Плюсы и минусы монолитной и микросервисной архитектуры</span></summary>
<br />

### **1. Монолитная архитектура**

Подходит для небольших команд, стартапов и систем с невысокой сложностью бизнес-логики.

| Характеристика         | Плюсы (+)                                                                           | Минусы (−)                                                                                               |
| ---------------------- | ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| **Разработка**         | **Простота:** единый код, общие модели данных и легкая навигация по проекту.        | **Запутанность:** со временем код превращается в «большой ком грязи», который трудно менять.             |
| **Тестирование**       | **Легкость:** можно запустить всё приложение целиком и провести сквозные тесты.     | **Риск:** небольшое изменение в одном модуле может неожиданно сломать другую часть системы.              |
| **Производительность** | **Скорость:** вызовы функций внутри памяти происходят мгновенно, без задержек.      | **Барьер роста:** нельзя масштабировать только одну нагруженную функцию — нужно копировать весь монолит. |
| **Деплой**             | **Удобство:** нужно доставить и запустить всего один артефакт (файл или контейнер). | **Долгое ожидание:** сборка и запуск огромного проекта могут занимать десятки минут.                     |

---

### **2. Микросервисная архитектура**

Оправдана в крупных проектах с сотнями разработчиков и необходимостью гибкого масштабирования.

| Характеристика         | Плюсы (+)                                                                                      | Минусы (−)                                                                                              |
| ---------------------- | ---------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| **Масштабирование**    | **Точечность:** можно добавить мощности только сервису оплаты или поиска, не трогая остальное. | **Сложность:** требуется сложная настройка инфраструктуры (Kubernetes, Service Mesh).                   |
| **Отказоустойчивость** | **Изоляция:** если «упал» сервис рекомендаций, каталог и корзина продолжат работать.           | **Сетевые сбои:** вызовы по сети могут обрываться, зависать или приходить с задержками.                 |
| **Стек технологий**    | **Гибкость:** можно использовать разные языки (Go для скорости, Python для ML) под задачи.     | **Зоопарк технологий:** трудно поддерживать единые стандарты качества и безопасности в разных командах. |
| **Командная работа**   | **Автономия:** команды работают независимо, не мешая друг другу и не дожидаясь чужих правок.   | **Согласованность:** трудно поддерживать актуальность данных в разных БД (проблема целостности).        |

> _Пример выбора:_ Если вы делаете MVP приложения для доставки еды — выбирайте **монолит**. Если вы строите гиганта уровня Uber или Amazon — вам не обойтись без **микросервисов**.

</details>

---

<details>
<summary><span>11. Где может происходить <b> балансировка нагрузки?</b></span></summary>
<br />

- **Клиентская балансировка** — клиент сам знает адреса серверов и выбирает, к какому обратиться.

  > _Пример:_ Клиентское приложение получает список IP-адресов от Service Discovery и само решает, куда слать запрос.

- **Серверная балансировка** — между клиентом и серверами стоит посредник (Load Balancer), который принимает все запросы и распределяет их.

  > _Пример:_ Nginx или HAProxy, стоящие перед кластером серверов.

- **DNS / GeoDNS балансировка** — распределение на уровне разрешения доменного имени. GeoDNS направляет пользователя на ближайший к нему дата-центр.
  > _Пример:_ Запрос из Европы направляется на сервер во Франкфурте, а из Азии — в Сингапур.

</details>

---

<details>
<summary><span>12. Какие есть <b>алгоритмы распределения нагрузки?</b></span></summary>
<br />

- **Random (Рандом)** — выбор случайного сервера. Просто, но может привести к неравномерной нагрузке.
- **Round Robin (RR)** — запросы передаются серверам по очереди (1-й, 2-й, 3-й и снова 1-й).
- **Weighted Round Robin (WRR)** — то же самое, но с учетом мощности (веса) сервера.

  > _Пример:_ Мощный сервер получает 3 запроса, а слабый — только 1.

- **Least Connections / Response Time / Bandwidth** — запрос уходит серверу с наименьшим количеством активных соединений, самым быстрым ответом или свободной полосой пропускания.
- **Power of Two Choices** — выбираются два случайных сервера, и из них запрос уходит тому, кто меньше нагружен. Это эффективнее, чем просто Random.
- **Sticky Sessions (Сессии)** — закрепление конкретного пользователя за конкретным сервером (обычно через Cookie).
  > _Пример:_ Нужно в **Stateful** архитектурах, чтобы корзина пользователя не «потерялась» при переходе на другой сервер.
  </details>

---

<details>
<summary><span>13. Какие есть <b>уровни балансировки (OSI) нагрузки?</b></span></summary>
<br />

- **L4 (Транспортный уровень)** — балансировка на основе IP и портов. Очень быстрая, так как не читает содержимое пакета.
- **L7 (Прикладной уровень)** — балансировка на основе содержимого запроса (URL, заголовки, Cookies). Позволяет делать умную маршрутизацию.
  > _Пример:_ Запросы `/api/video` отправлять на одни серверы, а `/api/images` — на другие.

</details>

---

<details>
<summary><span>14. Какие есть <b>виды проксирования?</b></span></summary>
<br />

- **Forward Proxy (Прямой прокси)** — сервер, который стоит между группой клиентов и интернетом. Он скрывает личность клиента от сервера и контролирует исходящий трафик.

  > _Пример:_ Корпоративный прокси в офисе, который запрещает сотрудникам заходить в соцсети или скрывает их реальные IP-адреса от внешних сайтов.

- **Reverse Proxy (Обратный прокси)** — сервер, который стоит перед одним или группой веб-серверов. Он принимает запросы из интернета и распределяет их между внутренними серверами. Клиент даже не знает, что общается не напрямую с целевым сервером.
  > _Пример:_ **Nginx** или **HAProxy**, которые стоят «на входе» в систему. Они занимаются балансировкой нагрузки, шифрованием (SSL-терминация) и кэшированием статики.

---

**Ключевое отличие:**

- **Forward Proxy** защищает и анонимизирует **клиента**.
- **Reverse Proxy** защищает и оптимизирует работу **сервера**.

**Reverse Proxy** — это «сердце» любой современной архитектуры. Он не только распределяет нагрузку, но и может выполнять роль **API Gateway**.

</details>

---

<details>
<summary><span>15. Для чего нужно <b>кэширование?</b></span></summary>
<br />

**Кэширование** — это один из самых эффективных способов ускорить систему и снизить нагрузку на базу данных за счет временного хранения часто запрашиваемых данных в быстрой памяти (RAM).

**Зачем оно нужно:**

1. **Ускорение отклика:** Данные из памяти отдаются в десятки раз быстрее, чем из дисковой БД.
2. **Снижение нагрузки на БД:** Повторные запросы не «дергают» тяжелую базу.
3. **Экономия ресурсов:** Уменьшается потребление CPU и сетевого трафика на повторные вычисления.

---

**Ключевые термины:**

- **Cache Hit (Попадание в кэш)** — успешная ситуация, когда запрошенные данные были найдены в кэше и сразу отданы клиенту.
- **Cache Miss (Промах)** — ситуация, когда данных в кэше не оказалось, и системе пришлось идти за ними в медленную базу данных.
- **Hit Ratio** — метрика эффективности кэша. Отношение количества «попаданий» к общему числу запросов.

  > _Пример:_ Если из 100 запросов 90 были отданы из кэша, Hit Ratio = 90%. Чем он выше, тем лучше настроен кэш.

- **Инвалидация кэша** — процесс удаления или обновления устаревших данных в кэше, чтобы пользователь не видел неактуальную информацию.

  > _Пример:_ Когда цена товара в БД изменилась, нужно «инвалидировать» старую цену в кэше, иначе клиент увидит неверную стоимость.

- **Прогрев кэша (Warm-up)** — предварительное заполнение кэша данными (обычно сразу после запуска системы), чтобы первые пользователи не столкнулись с медленной работой из-за _Cache Miss_.

  > _Пример:_ Скрипт, который после деплоя «прокликивает» самые популярные страницы, чтобы они попали в кэш.

- **Горячий ключ (Hot Key)** — это ключ (данные), к которому обращается аномально большое количество пользователей одновременно.
  > _Пример:_ Пост знаменитости с миллионами подписчиков или страница товара в «Черную пятницу». Горячие ключи могут перегрузить даже сам сервер кэширования.

</details>

---

<details>
<summary><span>16. Какие данные стоит кэшировать?</span></summary>
<br />

Выбор данных для кэширования обычно основывается на принципе **«часто запрашиваются, редко меняются»**.

- **Статические файлы** — изображения, JS/CSS скрипты, шрифты. Это самый простой и эффективный вид кэширования.

  > _Пример:_ Логотип компании на главной странице, который не меняется годами.

- **Результаты тяжелых запросов к БД** — данные, на получение которых уходит много времени и ресурсов сервера.

  > _Пример:_ Список топ-100 популярных товаров, который собирается из нескольких огромных таблиц с агрегацией.

- **Данные профилей пользователей (сессии)** — информация о том, авторизован ли пользователь и какие у него права.

  > _Пример:_ Имя пользователя и его аватар, которые отображаются на каждой странице сайта.

- **Ответы от внешних API** — если ваша система запрашивает данные у сторонних сервисов, которые работают медленно или берут деньги за каждый запрос.

  > _Пример:_ Курс валют от ЦБ, который обновляется раз в сутки, или прогноз погоды.

- **Результаты сложных вычислений** — данные, требующие больших затрат CPU.
  > _Пример:_ Сформированный PDF-отчет за прошлый месяц или результат работы алгоритма рекомендаций.

---

**Что НЕ стоит кэшировать:**

1. **Часто меняющиеся данные:** Если данные обновляются раз в секунду, кэш будет постоянно инвалидироваться и не принесет пользы.
2. **Персональные/секретные данные других пользователей:** Ошибка в логике кэширования может привести к тому, что один пользователь увидит данные карты другого.
3. **Данные с низкой вероятностью повторного использования:** Кэширование редких запросов («Хвост» или Long Tail) только тратит дорогую память RAM.

Важно помнить про **Read / Write Ratio**: чем больше система ориентирована на чтение (Read-heavy), тем больше пользы принесет кэширование.

</details>

---

<details>
<summary><span>17. Нужно ли <b>кэширование ошибок?</b></span></summary>
<br />

Кэширование ошибок (также известное как **Negative Caching**) — это продвинутая техника, которая помогает защитить систему от «эффекта домино» при сбоях или атаках.

**Да, это необходимо**, но с определенными условиями. Кэширование ответов об отсутствии данных или временных сбоях предотвращает перегрузку системы.

**Зачем это нужно:**

- **Защита от «мусорных» запросов:** Если кто-то (или бот) запрашивает несуществующие данные миллион раз, система не будет каждый раз обращаться к БД, а сразу отдаст ошибку из кэша.
- **Снижение нагрузки при сбоях:** Если база данных временно недоступна, кэширование ошибки позволит серверу не тратить время на ожидание тайм-аута при каждом новом запросе.

---

**Что именно кэшировать:**

- **Ошибка 404 (Not Found)** — если ресурса нет, лучше запомнить это на короткое время.

  > _Пример:_ Запрос профиля пользователя, который был удален.

- **Ошибки авторизации (401/403)** — помогает защититься от Brute-force атак (подбора паролей).
- **Пустые результаты поиска** — если по запросу «розовый слон в скафандре» ничего не найдено, нет смысла искать это снова в следующие 5 минут.

---

**Главные правила (Best Practices):**

1. **Короткий TTL (Time To Live):** Ошибки должны жить в кэше гораздо меньше, чем успешные ответы.

   > _Пример:_ Успешный ответ кэшируем на 1 час, а ошибку 404 — на 1-2 минуты.

2. **Разделение типов ошибок:** Нельзя кэшировать ошибку 500 (Internal Server Error) надолго, так как она может быть исправлена через секунду.
3. **Безопасность:** Убедитесь, что закэшированная ошибка не содержит чувствительной информации о структуре вашей системы или БД.

Кэширование ошибок — это отличный способ повысить **Доступность** системы под нагрузкой.

</details>

---

<details>
<summary><span>18. Всегда ли кэширование полезно?</span></summary>
<br />

Нет, кэширование — это не всегда благо. В некоторых сценариях оно может не только быть бесполезным, но и навредить производительности или корректности данных.

Кэширование становится вредным или неэффективным в следующих случаях:

- **Низкий Hit Ratio (Редкие запросы)** — если данные запрашиваются повторно крайне редко, кэш просто занимает дорогую оперативную память, не принося пользы.

  > _Пример:_ База данных пользователей огромная, а люди заходят в профиль раз в год. Кэшировать все профили — пустая трата ресурсов.

- **Write-heavy нагрузка (Частые обновления)** — если данные меняются чаще, чем читаются, система будет тратить больше ресурсов на постоянную инвалидацию и обновление кэша, чем на само чтение.

  > _Пример:_ Котировки акций в реальном времени. Кэш станет неактуальным через миллисекунду после записи.

- **Критическая важность свежести данных** — в финансовых или медицинских системах даже задержка в пару секунд может быть недопустима.

  > _Пример:_ Баланс банковского счета. Пользователь не должен видеть старую сумму после того, как он только что снял деньги.

- **Ограниченность ресурсов (RAM)** — кэш живет в оперативной памяти, которая намного дороже дискового пространства. Если кэшировать всё подряд, системе не хватит памяти для выполнения основных процессов.
- **Усложнение логики (Проблема консистентности)** — поддержка кэша в актуальном состоянии требует сложного кода. Ошибки в инвалидации кэша — одна из самых частых причин багов, которые сложно воспроизвести.
  > _Пример:_ Пользователь сменил пароль, но кэш сессии на одном из серверов не обновился, и старый пароль всё еще работает.

---

**Когда кэш превращается в проблему:**

1. **Cache Stampede (Гонка за кэшем):** Когда у популярного ключа истекает срок жизни, и тысячи запросов одновременно «ломятся» в базу данных, чтобы обновить его, создавая лавинообразную нагрузку.
2. **Pollution (Загрязнение кэша):** Когда «одноразовые» данные вытесняют из памяти действительно полезные и часто используемые данные.

Именно поэтому перед внедрением кэша всегда стоит оценить **Read/Write Ratio** и выбрать правильную **стратегию вытеснения данных** (например, **LRU** — Least Recently Used).

</details>

---

<details>
<summary><span>19. Как <b>рассчитать эффективность кэша</b>?</span></summary>
<br />

Основной метрикой является **Среднее время доступа (Average Access Time)**.

$$T_{avg} = (HitRate \times T_{cache}) + (MissRate \times T_{db})$$
Где:

- **$Hit Rate$** — доля запросов, найденных в кэше (от 0 до 1).
- **$Miss Rate$** — доля запросов, которых не оказалось в кэше (1 - HitRate).
- **$T\_{cache}$** — время получения данных из кэша.
- **$T\_{db}$** — время получения данных из основного хранилища (БД).

---

### **Когда кэш становится вредным?**

Существует «правило большого пальца»: если **Cache Miss Rate > 0.8** (то есть вы не находите данные в кэше более чем в 80% случаев), кэш считается вредным.

**Почему это плохо:**

1. **Double Latency:** При промахе вы тратите время $T_{cache} + T_{db}$. Если промахов 80%, то для большинства запросов система работает медленнее, чем вообще без кэша.
2. **Бесполезный расход ресурсов:** Вы тратите дорогую оперативную память (RAM) и CPU на поддержку структуры кэша, которая не выполняет свою задачу.
3. **Засорение:** При таком высоком Miss Rate данные в кэше постоянно обновляются, создавая лишнюю нагрузку на запись в сам кэш.

> _Пример:_ > Допустим, время в кэше 1 мс, в БД 100 мс.
> Если **Miss Rate = 0.9** (90%), то $T\_{avg}$ = (0.1 $\times$ 1) + (0.9 $\times$ 101) $\approx$ 91 мс.
> Накладные расходы на проверку кэша в 90% случаев делают систему менее эффективной.

---

### **Как повысить эффективность (Hit Ratio)?**

- **Увеличить TTL:** Хранить данные дольше (если бизнес-логика позволяет).
- **Увеличить объем памяти:** Чтобы популярные данные не вытеснялись новыми.
- **Прогрев кэша:** Заполнять его данными до прихода реальных пользователей.

</details>

---

<details>
<summary><span>20. Какие есть <b>виды кэширования?</b>, плюсы и минусы?</span></summary>
<br />

### **1. Внутреннее кэширование (In-memory cache)**

Данные хранятся непосредственно в оперативной памяти самого приложения (например, в HashMap или специальных библиотеках вроде Caffeine/Guava).

| Плюсы (+)                                                                                                            | Минусы (−)                                                                                                                      |
| -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| **Экстремальная скорость:** данные читаются из памяти процесса, это самый быстрый способ.                            | **Проблемы масштабирования:** при горизонтальном масштабировании у каждого экземпляра приложения будет свой «кусочек» кэша.     |
| **Нет сетевых задержек:** не нужно обращаться к другому серверу.                                                     | **Трудности синхронизации:** если на Сервере А данные в кэше обновились, Сервер Б об этом не узнает (проблема консистентности). |
| **Нет расходов на (un)marshalling:** данные хранятся как готовые объекты языка, их не нужно превращать в JSON/байты. | **Прогрев после падения:** если приложение упадет, кэш полностью очистится и его придется наполнять с нуля.                     |

> _Пример:_ Хранение конфигурационных файлов или справочников стран, которые редко меняются.

---

### **2. Внешнее кэширование (Distributed cache)**

Кэш вынесен в отдельную систему (базу данных в памяти), к которой обращаются все экземпляры приложения.

> _Пример:_ Redis, Memcached.

| Плюсы (+)                                                                                  | Минусы (−)                                                                                                                            |
| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| **Общее состояние:** все серверы видят одни и те же актуальные данные.                     | **Скорость работы:** ниже, чем у внутреннего, так как добавляются сетевые задержки (Network Latency).                                 |
| **Масштабируемость:** можно хранить терабайты данных, просто добавляя узлы в кластер кэша. | **Маршалинг данных:** данные нужно сериализовать (например, в JSON или Protobuf), чтобы отправить по сети, и десериализовать обратно. |
| **Живучесть:** если приложение упадет и перезапустится, данные в кэше сохранятся.          | **Точка отказа:** если упадет сам Redis, «ослепнут» сразу все серверы приложения.                                                     |

> _Пример:_ Хранение сессий пользователей или корзин покупок в интернет-магазине.

---

**Итог:**

- Если данных мало и они статичны — используй **внутренний** кэш.
- Если система распределенная и данных много — выбирай **внешний**.

</details>

---

<details>
<summary><span>21. Какие есть <b>способы взаимодействия с кэшем</b>?</span></summary>
<br />

### **Стратегии чтения (Read)**

- **Cache Aside (Кэширование на стороне)** — приложение сначала идет в кэш; если данных нет (miss), читает из БД и само сохраняет их в кэш.

  > _Пример:_ Самый популярный подход. Приложение управляет всем процессом, а БД и кэш не знают друг о друге.

- **Read Through** — приложение всегда запрашивает данные только у кэша, а кэш сам идет в БД при промахе, обновляется и возвращает ответ.
  > _Пример:_ Позволяет упростить код приложения, переложив логику чтения на инфраструктуру кэша.

### **Стратегии записи (Write)**

- **Write Through** — данные записываются одновременно и в кэш, и в БД; запись считается успешной только после подтверждения от обоих.

  > _Пример:_ Гарантирует высокую актуальность данных в кэше, но замедляет запись из-за двойной операции.

- **Write Back (или Write Behind)** — приложение пишет данные только в кэш, а в БД они сохраняются асинхронно через некоторое время.

  > _Пример:_ Очень быстрая запись, подходит для систем сбора логов или счетчиков, где потеря нескольких секунд данных не критична.

- **Write Around** — данные пишутся напрямую в БД, минуя кэш. Кэш обновляется только при последующем чтении (через Cache Aside).
  > _Пример:_ Помогает не засорять кэш данными, которые записываются часто, но читаются редко.

### **Дополнительные техники**

- **Refresh-ahead (Cache Ahead)** — кэш автоматически обновляет данные до того, как истечет их срок жизни (TTL), если они часто запрашиваются.
  > _Пример:_ Система видит, что срок жизни популярной новости истекает через 10 секунд, и заранее делает запрос к БД, чтобы пользователь не столкнулся с ожиданием (latency).

Каждая из этих стратегий — это выбор между **скоростью** и **риском потери данных** или их рассогласования.

</details>

---

<details>
<summary><span>22. Какие есть <b>алгоритмы вытеснения данных?</b></span></summary>
<br />
Когда кэш переполняется, системе нужно решить, какие данные удалить, чтобы освободить место для новых. Эти правила называются **алгоритмами вытеснения (Eviction Policies)**.

### **Базовые алгоритмы**

- **Random (Рандом)** — удаляет случайный объект. Прост в реализации, но не учитывает полезность данных.
- **FIFO (First In, First Out)** — удаляет данные, которые были добавлены первыми (как в очереди), независимо от того, как часто их читали.
- **LIFO (Last In, First Out)** — удаляет данные, которые были добавлены последними. Используется редко.

### **Алгоритмы на основе обращения**

- **LRU (Least Recently Used)** — удаляет данные, которые **дольше всего не запрашивались**. Самый популярный алгоритм (баланс простоты и эффективности).
- **MRU (Most Recently Used)** — удаляет данные, которые запрашивались **последними**. Полезен, когда старые данные с большей вероятностью понадобятся снова.
- **LFU (Least Frequently Used)** — удаляет данные, которые запрашивались **реже всего** (считает количество обращений).
  > _Минус:_ старые популярные объекты могут «застрять» в кэше навсегда.

### **Продвинутые и комбинированные алгоритмы**

- **LRU-k** — учитывает время k-го последнего обращения. Позволяет лучше отличать популярные данные от случайных «разовых» запросов.
- **SLRU (Segmented LRU)** — кэш делится на две зоны: «пробная» (для новых данных) и «защищенная» (для часто запрашиваемых).
- **2Q (Two Queues)** — использует две очереди (FIFO и LRU), чтобы эффективно отсеивать данные, которые запрашиваются только один раз (защита от «сканирования» кэша).
- **TLRU (Time-aware LRU)** — учитывает не только время последнего обращения, но и срок жизни данных (TTL).

### **Аппроксимации и спец. алгоритмы**

- **Second Chance (Второй шанс)** — модификация FIFO. Если у элемента стоит «флаг обращения», ему дается второй шанс, и он перемещается в конец очереди вместо удаления.
- **Clock (Часы)** — более эффективная реализация Second Chance, где элементы стоят по кругу, а «стрелка» ищет кандидата на удаление.
- **Алгоритм Белади (OPT)** — теоретический идеал. Удаляет данные, которые не понадобятся **дольше всего в будущем**.
  > _Нюанс:_ Невозможен на практике, так как мы не знаем будущего. Используется как эталон для сравнения других алгоритмов.

В современных системах (например, в **Redis**) чаще всего используется **LRU** или его аппроксимации, так как они дают лучший результат при минимальных затратах ресурсов.

</details>

---

<details>
<summary><span>23. Какие есть <b>виды API?</b></span></summary>
<br />

### **1. REST (Representational State Transfer)**

Самый популярный стиль для веб-сервисов. Строится вокруг **ресурсов** (сущностей), доступ к которым осуществляется через стандартные HTTP-методы (**CRUD**).

- **Методы:** `GET` (чтение), `POST` (создание), `PUT/PATCH` (обновление), `DELETE` (удаление).
- **Плюсы:** Простота, кэширование, независимость клиента и сервера. Обычно использует JSON.

### **2. SOAP (Simple Object Access Protocol)**

Строгий протокол на базе XML. Часто встречается в банковских системах и старом корпоративном ПО.

- **Особенности:** Имеет жесткий стандарт (WSDL-файл), встроенную обработку ошибок и поддержку безопасности (WS-Security).
- **Плюсы:** Высокая надежность и строгость данных. **Минусы:** Избыточность (тяжелый XML) и сложность.

### **3. RPC (Remote Procedure Call)**

Концепция «вызова удаленной процедуры». Клиент вызывает функцию на сервере так, будто она находится в его собственном коде.

- **gRPC (Google RPC)** — современная реализация от Google. Использует **HTTP/2** и формат **Protocol Buffers** (бинарный код).
- **Плюсы:** Экстремально высокая скорость, двусторонняя потоковая передача данных, строгая типизация.
- **Минус:** Не читается человеком (нужна десериализация), сложно тестировать через браузер.

### **4. GraphQL**

Язык запросов для API, созданный Facebook. Позволяет клиенту самому определять, какие именно поля ему нужны.

- **Особенности:** У клиента есть одна точка входа (`/graphql`), куда он отправляет запрос с описанием структуры данных.
- **Плюсы:** Решает проблему **Overfetching** (лишние данные) и **Underfetching** (недостаток данных, требующий новых запросов).
- **Минус:** Сложность реализации на сервере и трудности с кэшированием.

---

**Краткое сравнение:**

- Нужен стандарт для фронтенда? — **REST**.
- Нужна скорость между микросервисами? — **gRPC**.
- Сложные данные и мобильные приложения? — **GraphQL**.
- Банковский сектор 15-летней давности? — **SOAP**.

</details>

---

<details>
<summary><span>24. Что такое <b>Underfetching</b> и <b>Overfetching</b> и как они связаны с GraphQL?</span></summary>
<br />

Эти термины описывают неэффективность передачи данных между клиентом и сервером.

### **1. Overfetching (Избыточная выборка)**

Это ситуация, когда клиент получает от сервера **больше данных, чем ему нужно** для отрисовки конкретного экрана.

- **Проблема:** Тратится лишний мобильный трафик, расходуется заряд батареи на парсинг тяжелых JSON-ответов, нагружается сеть.
- **Пример в REST:** Чтобы показать только _имена_ друзей в списке, вы вызываете `/api/friends`. Но сервер возвращает полный объект каждого друга: дату рождения, адрес, историю заказов и биографию. 90% этих данных вам сейчас не нужны.

### **2. Underfetching (Недостаточная выборка)**

Это ситуация, когда одного запроса к API **недостаточно**, чтобы получить все необходимые данные для экрана.

- **Проблема:** Клиенту приходится делать несколько последовательных (цепочечных) запросов, что увеличивает время ожидания (**Latency**) из-за постоянных сетевых «походов».
- **Пример в REST:** Вам нужно показать профиль пользователя и его последние 3 поста. Сначала вы делаете запрос `/user/1`, получаете ID постов, а затем делаете второй запрос `/user/1/posts`. Пока не завершится первый, вы не можете начать второй.

---

### **Внутреннее устройство (Как это решает GraphQL)**

В отличие от REST, где каждый URL — это фиксированный набор данных, **GraphQL** работает иначе:

1. **Единая точка входа (Endpoint):** Обычно это один URL (например, `/graphql`).
2. **Схема (Schema):** На сервере описываются все возможные типы данных и связи между ними (сильная типизация).
3. **Запрос (Query):** Клиент сам пишет структуру запроса, перечисляя только нужные поля.

   > _Решение Overfetching:_ Если вам нужно только `name`, вы пишете `name` в запросе, и сервер пришлет только его.

   > _Решение Underfetching:_ Вы можете в одном запросе попросить и данные профиля, и вложенный список постов. Сервер сам соберет их и отдаст одним ответом.

</details>

---

<details>
<summary><span>25. Что такое <b>Observability</b> и из чего она состоит?</span></summary>
<br />

**Observability** — это способность понимать внутреннее состояние системы, анализируя данные, которые она выдает наружу. Она состоит из «трех столпов» и дополнительных методов:

- **Monitoring (Мониторинг) & Metrics** — сбор числовых данных о работе системы в реальном времени. Помогает ответить на вопрос: «Система здорова?».
- **Logging (Логирование)** — запись текстовых событий. Помогает ответить на вопрос: «Что именно произошло?».
- **Tracing (Трейсинг)** — отслеживание пути одного конкретного запроса через все микросервисы. Помогает ответить на вопрос: «Где именно возникла задержка?».
- **Continuous Profiling (Непрерывное профилирование)** — анализ потребления ресурсов (CPU, RAM) на уровне строк кода в реальном времени.
- **Анализ сбоев (Error Analysis)** — автоматический сбор и группировка исключений (exceptions).

## </details>

---

<details>
<summary><span>26. Основные <b>метрики производительности</b></span></summary>
<br />

### **1. Метрики нагрузки и пропускной способности (Throughput)**

- **RPS (Requests Per Second)** — количество входящих запросов к серверу в секунду.
- **TPS (Transactions Per Second)** — количество успешно завершенных бизнес-операций (например, оплат или регистраций).
- **QPS (Queries Per Second)** — количество обращений к базе данных (обычно выше, чем RPS, так как один запрос может порождать несколько обращений к БД).

### **2. Метрики времени и качества (Latency & Reliability)**

- **Response Time (Время отклика)** — полное время обработки запроса. Важно смотреть на **перцентили**:
- **p50 (Медиана):** среднее время для обычного пользователя.
- **p99:** время, которое видят 1% пользователей с самыми медленными запросами (критично для SLA).

- **Error Rate (Уровень ошибок)** — доля ответов с кодами 4xx и 5xx. Резкий рост этой метрики — главный сигнал об аварии.

### **3. Метрики ресурсов (Utilization)**

- **Infrastructure:** загрузка CPU (процессор), RAM (память), Traffic (сетевой канал) и Disk I/O (чтение/запись на диск).
- **Runtime:** количество активных процессов/потоков (Threads) и интенсивность работы сборщика мусора (GC Pause).

### **4. Состояние очередей и доступность**

- **Queue Depth (Размер очередей):** количество запросов, ожидающих обработки. Рост очереди — предвестник роста _Response Time_.
- **Uptime / Downtime:** время доступности и простоя системы в процентах (например, "четыре девятки" — 99.99%).

</details>

---

<details>
<summary><span>27. Стек инструментов <b>Observability</b></span></summary>
<br />

Для каждой задачи в индустрии сложились свои стандарты (De Facto):

| Направление        | Инструменты (Stack)                       | Описание                                                                                       |
| ------------------ | ----------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **Мониторинг**     | **Prometheus** + Grafana                  | **Prometheus** — стандарт для сбора метрик (pull-модель). Grafana — для визуализации графиков. |
| **Логирование**    | **ELK** (Elasticsearch, Logstash, Kibana) | Logstash собирает, Elasticsearch хранит и ищет, Kibana показывает логи.                        |
| **Трейсинг**       | **Jaeger**, Zipkin                        | Позволяют увидеть «дерево» вызовов: как запрос прошел через 10 микросервисов.                  |
| **Профилирование** | **Pyroscope**, Parca                      | Показывают "Flame Graphs" — какие функции в коде едят больше всего CPU прямо сейчас.           |

</details>

---

<!-- <details>
<summary><span></span></summary>
<br />

</details>

--- -->
